{"pageProps":{"frontmatter":{"title":"Fairness by Discussion","metaTitle":"Fairness by Discussion","metaDescription":"A non-computational approach to Fairness in the context of negotiations. My Bachelor's thesis.","abstract":"The field of automated negotiation promises to improve negotiations, thus, a fair outcome and process should also be considered when building these systems. However, issues exist with computational approaches to fairness with which the field of computer science is mainly concerned. To this end, we propose a new approach to fairness based on that of essentially contested concepts to see if argumentation-based negotiation could be used as an extension to the Stacked Alternating Offers Protocol to improve fairness. Looking at fairness as an essentially contested concept shows that discussion between people somehow influenced by the negotiation system is necessary to maintain its fairness. This in turn means that systems that provide accessible context are fairer than systems that would not do so. Thus arguments, if implemented in an accessible manner, add more context to the negotiation, in turn making an SAOP negotiation fairer.","author":"Zohar Cochavi","date":"2022-07-02","tags":["thesis (bsc)","fairness","philosophy","ai"]},"content":"\n## Introduction\n\nFairness in computation, especially machine learning is a topic that has\ngotten increasing attention, and with good reason. COMPAS was a\nstatistical tool that aided some U.S. states in determining how likely\nan individual was to recommit a crime. The tool, however, could display\nsignificant racial bias towards black individuals further reinforcing\nbias in human decision-making (“Fairness in Machine Learning” 2020).\n\nAnother field trying to augment human decision-making using computation\nis that of automated negotiation. It promises to improve the outcome,\nand process of negotiations by assisting humans or replacing them\naltogether (Baarslag et al. 2017). To be clear, there have not been such\ndrastic fairness-related harms in automated negotiation, but that does\nnot mean there never will be. Especially since machine learning tools\nare also being used to improve the performance of these negotiating\nagents (the computer program negotiating on behalf of a party) in, for\nexample, opponent modeling[^1] (He et al. 2016).\n\nThis raises the question: Would there be a way in which we could improve\nthe fairness of automated negotiations? The question in and of itself is\ntoo broad and has to be scoped down in order to be meaningfully\nanswered. Starting with fairness and the eternal discussion regarding\nthe subject.\n\n### Fairness is Hard\n\nGiving a single good definition of fairness is in no way trivial.\nSomething Gallie (1955) also observed. In his research, he coined the\nterm of an _essentially contested concept_, which tries to answer the\nquestions of why some concepts are to hard to define in a general\ncontext.\n\nFairness being an essentially contested concept could imply that on some\ntopics there cannot be a single agreed definition. If that is the case,\nperhaps creating a system in which definitions are more easily\ninvestigated and adapted could be considered fairer.\n\nThe relevance of an essentially contested concept is further emphasized\nby the history of fairness in philosophy. Simply look at the number of\nopinions on fairness, or most any topic, all taking vastly different\nangles in an attempt to define the concept (Rawls 1973; Wolff 1998).\n\nEven though there is discussion around fairness in computer science, the\ndiscussion does not seem to be as diverse as in philosophy. In a lot of\nresearch, similar approaches are taken and mostly based on computational\nor statistical approaches to fairness (Cerbone 2021; Jacobs and Wallach\n2021).\n\nAlthough using computational approaches to the topic makes sense in the\ncontext of computer science, some researchers have raised concerns about\ncomputational approaches to fairness (Jacobs and Wallach 2021). This\nfurther motivates the need for a different approach to fairness in\ncomputation and thus automated negotiations.\n\n### On Negotiation\n\nOne way in which we could influence the fairness of negotiations is by\nestablishing certain rules one has to follow during the negotiation. The\nset of rules followed during a negotiation is called a _negotiation\nprotocol_.\n\nOne example of such a protocol is _SAOP_ or the _Stacked Alternating\nOffers Protocol_ (Aydoğan et al. 2017). In this protocol parties present\nproposals in an alternating fashion, with one party initiating the\nprocess. At each proposal, the other party (or parties) can choose to\naccept the offer, or propose a counter-offer , to which the other party\ncan respond again by accepting or proposing a counter-offer, etc. This\nprotocol is one of the most basic ones, pay attention next time you\nhaggle for a new car at the dealer, most probably you will follow the\nrules of SAOP.\n\nIf you decide to rely on a seller's empathy by arguing that you really\ncannot afford that price, you are employing an _Argumentation Based\nNegotiation_ protocol or _ABN_ protocol. While not technically a\ncomplete protocol, allowing the usage of arguments is part of a\nprotocol[^2]. In these types of negotiations, a party is allowed to\nprovide reasoning behind their proposal in order to inform, or possibly\nmanipulate, an adversary (Rahwan et al. 2004).\n\nThese kinds of negotiations are interesting because they contain more\ninformation about the motivations of a party than SAOP. Especially in\nthe context of automated negotiations as we will be able to see why an\nagent makes certain decisions (Rahwan et al. 2004). Furthermore, they\ncan be mathematically proven to be able to allow parties to reach a more\nsatisfying agreement more quickly (Jennings et al. (2001), p.205).\n\nOf course, more properties of negotiations exist. Another elementary\nexample is direct negotiation between two individuals, called a\n_bilateral negotiation_. This differs from, for example, the negotiation\nmethod used when buying a house where a real estate agent acts as a\n_mediator_ through which the parties bid. In addition to these two,\nthere is a more 'general' type of negotiation, namely a _multilateral_\nnegotiation. Simply said, this type of negotiation is one in which more\nthan two parties are involved.\n\n### Outline\n\nGiven that the usage of arguments provides a great advantage, it is\ninteresting to investigate if it could be considered as an extension to\nSAOP to improve fairness. The simplicity of SAOP makes it a good\ncandidate for determining how much fairer a negotiation would be _with_\narguments instead of _without_ since we will be able to focus solely on\nthe impact arguments have on the fairness of a negotiation.\n\nTo this end, we consider the fairness of SAOP and that of ABN in the\ncontext of fairness as an essentially contested concept. In short, with\nthis definition, we will be able to consider fairness for automated\nnegotiations without having to solely rely on computations. We thus take\na different angle at the problem than other approaches in computer\nscience (Pessach and Shmueli 2020; Cerbone 2021; Dwork et al. 2011),\nallowing us to resolve concerns some researchers have raised about such\napproaches (Jacobs and Wallach 2021; DeBrusk 2018).\n\nBecause of its importance, we will start with a larger discussion on\nfairness in <span class=\"spurious-link\"\ntarget=\"Fairness by Discussion\">_Fairness by Discussion_</span> in which\nwe will cover how we define fairness and why. After that we consider the\nimpact arguments would have on the fairness of SAOP in\n<span class=\"spurious-link\"\ntarget=\"Accessible Argumentation Drives Discussion\">_Accessible\nArgumentation Drives Discussion_</span>. We discuss some topics for\nfuture study or discussion in <span class=\"spurious-link\"\ntarget=\"Other Remarks\">_Other Remarks_</span> and conclude the argument\nin <span class=\"spurious-link\" target=\"A Promising Argument\">_A\nPromising Argument_</span>.\n\n## Fairness by Discussion\n\nTo assess the protocols in terms of _fairness_, the term has to be\nproperly defined. In this section, we will briefly explore current ideas\non fairness in computer science and philosophy in\n<span class=\"spurious-link\" target=\"A Brief History of Fairness\">_A\nBrief History of Fairness_</span>. Following that, we will further\nexplain what an essentially contested concept is and why \\[\\[Fairness is\nEssentially Contested\\]\\[Fairness is Essentially Contested\\]\\]. We then\nargue why discussion is necessary for an essentially contested concept\nin <span class=\"spurious-link\"\ntarget=\"The Necessity of Open Discussion\">_The Necessity of Open\nDiscussion_</span>, reflect back on what that means for fairness in\n<span class=\"spurious-link\" target=\"Back to Computation\">_Back to\nComputation_</span>, and summarize our findings in\n<span class=\"spurious-link\" target=\"Putting it Together\">_Putting it\nTogether_</span>.\n\n### A Brief History of Fairness\n\nPlenty of work exists on fairness in philosophy. One example is that of\nWolff, who considers fairness as follows:\n\n> Fairness is the demand that no one should be advantaged or\n> disadvantaged by arbitrary factors. (Wolff (1998), p.106)\n\nThe question then becomes, what is an _arbitrary factor_? and what does\nit mean to gain an advantage (or disadvantage) over someone else? While\nthese questions have been answered in numerous ways within the realm of\nphilosophy (Wolff 1998; Cerbone 2021; Rawls 1973), computer science is\nrather homogeneous in its opinion of fairness. Most popular answers fall\nsomewhere in between a _Rawlsian_ and _egalitarian_ view of the\ndistribution of goods or services (Pessach and Shmueli 2020; Cerbone\n2021).\n\nThere has been a growing amount of research into resolving these issues\nrelated to computational fairness, mainly through the awareness of bias,\nboth in systems and culture (DeBrusk 2018; Pessach and Shmueli 2020).\nThis gives researchers and policymakers great tools to determine where\n'unfairness' could originate from but does not solve the question of\nwhat explicitly would be unfair.\n\nGood reasons do exist for computer science to use the definitions of\nfairness it does now. As an example, in Dwork et al. (2011) the\ndefinition of fairness is a statistical model of 'similar individuals\nshould be treated similarly'; similar distributions should have similar\nmappings. Maximizing fairness is then a matter of minimizing the\ndistance between the distributions after the mapping. These models are\nrelatively easy to implement, quantifiable, and therefore easier to\nanalyze than more 'typical' philosophical descriptions of fairness (the\ntheories that take 20 pages to explain, and 20 years to understand).\n\nProblems, however, exist with 'computable' approaches to fairness. There\nis a potential for some significant fairness-related harms that come\nwith computational systems, as mentioned by Jacobs and Wallach (2021).\nThey argue that fairness cannot be computed without essentially\nsimplifying some parts of it. In turn, leading to possibly unfair\nscenarios because of simplifications that might be justifiable in all\nscenarios in which the model is used.\n\nOf course, this does not imply that no good definition of fairness\nexists in certain contexts, but it does go to show how contested the\ntopic is. Current computational approaches to fairness seem to do\nexactly as described; they somehow try to compute fairness. Which is the\ncause of the problems mentioned by Jacobs and Wallach (2021) and Kuhn\n(1996).\n\nHaving a definition that is independent of computation could therefore\nbe a good contributor to the discussion. This brings us back to the\nessentially contested nature of fairness and how it relates to\ndiscussions.\n\n### Fairness is Essentially Contested\n\nWe have previously given an informal definition of an essentially\ncontested concept, but the definition is more exact and has important\nimplications for our discussion. Formally, Gallie (1955) states four\nconditions a concept should satisfy to be considered essentially\ncontested:\n\n1. It must be appraisive in the sense that it signifies or accredits\n   some kind of valued achievement (Gallie (1955), p.171).\n2. This achievement must be of an internally complex character, for all\n   that its worth attributed to it as a whole (Gallie (1955), p.171).\n3. Any explanation of its worth must therefore include reference to the\n   respective contributions of its various parts or feature (Gallie\n   (1955), p.172).\n4. The accredited achievement must be of a kind that admits of\n   considerable modification in the light of changing circumstances;\n   and such modification cannot be prescribed or predicted in advance\n   (Gallie (1955), p.172).\n\nIn short, it is a concept that should (1) signify value, (2) be\nmultidimensional, i.e. there are multiple factors that all contribute to\nsomething being regarded as the concept, (3) it can only be _properly_\ndefined in context (the definition must therefore refer to its\ncontributions), and (4) be time-dependent. It is a concept that is\nconsidered valuable/important, but its definition is volatile concerning\ncontext.\n\n\\(1\\) Fairness is a valuable feature, there has been a lot of research\nin _trying_ to improve fairness in systems (computational as well as\norganizational), as covered in the previous section. You will rarely\nhear someone talk about trying to minimize the fairness of a system\nunless they are in a particularly sadistic mood.\n\n\\(2\\) Often, fairness does depend on more than one factor at once. Take\nagain the definition of fairness in terms of 'arbitrary factors' which,\nquite literally, depends on (the lack of) multiple factors. A less\nobvious example would be that of _Rawlsian_ fairness which depends on an\nindividual being able to be ignorant of his position in society (Rawls 1973) to form a fair judgment. This depends on an individual being able\nto be ignorant to extend that one is not able to 'see' their position in\nsociety, but not to such so far such that they are not aware of any\nother's position in said society, and it depends on those individuals\nbeing 'rational' and 'free persons' (Rawls (1973), p.11), etc.\n\n\\(3\\) Furthermore, fairness is only well-defined within context. It is\nnot hard to think of counterexamples of any type of fairness if the\ncontext in which it does hold is not part of the definition. Take for\nexample _egalitarianism_, which is the belief that resources should be\nshared equally[^3] (Wolff 1998). But what if the individuals do not put\nin the same amount of work to collect those resources? The definition\nshould therefore be: Resources will be shared equally among those who\nput in a similar amount of work[^4]. If the context is not well-defined,\nthe definition will be incomplete.\n\n\\(4\\) Furthermore, it is hard to predict what people will find fair in\nthe future. Take, for example, capital punishment. While prevalent\nthroughout European history, most countries have now abolished the\npractice and no longer consider it a fair form of punishment (Neumayer\n2008).\n\nNaturally, the theories presented here are slightly cherrypicked to\nprove my point. These are, however, definitely not the only ones and\nplenty more examples can be given.\n\n### The Necessity of Open Discussion\n\nAssuming that fairness is an essentially contested concept, we can\nexplore the relation between essentially contested concepts[^5] and\ndiscussions. This relation will show how arguments could contribute to a\nmore fair system.\n\nThe lack of a discussion about any concept could indicate a couple of\nthings: (I) either an agreement, (II) an 'agreement on disagreeing', or\nsimply (III) not realizing that there is a disagreement. We will go\nthrough each scenario, arguing why it would imply that discussion is\neventually necessary if that concept is essentially contested.\n\n\\(I\\) If there is an actual agreement, it means some definition is\naccepted. Considering that points (3) and (4) infer exactly that there\nis no single definition (since it is so sensitive to context) for an\nessentially contested concept, this implies that a discussion is\nnecessary for an essentially contested concept[^6]. Both because of the\nsimple passage of time that implies that the definition changes (4), and\nbecause different people have different backgrounds, i.e. different\ncontexts in which they think about fairness.\n\n\\(II\\) Secondly, the moment two parties decide not to discuss the topic,\nit does not mean that the discussion will never arise. We can argue that\nbecause of the valuable nature of an essentially contested concept (1),\npeople will have to argue about it at some point. This will, however,\nonly be the case if the subject is valuable enough.\n\nFairness could be considered valuable enough to eventually give rise to\ndiscussions. If one feels like they are being treated in unfairly, and\nthe situation is _open_, most anyone will say that they do not agree.\nHere, open, refers to a situation in which if an individual were to\nvoice their opinion on fairness they know that their context will be\n'added' to the definition of fairness. This means that more open\ndiscussions contain more context, and therefore fairer, definition of\nfairness.\n\n\\(III\\) In the last case, since the concept is regarded as valued (1),\nwe can again assume that, even if parties have not yet voiced their\nopinions, they will at some point do so. Thus concluding that discussion\nis indeed necessary for fairness as an essentially contested concept.\n\nOn the other hand, what happens if an individual cannot take part in the\ndiscussion? If individuals that are influenced by the given definition\nof a concept cannot contribute to the definition, i.e. their context is\nnot part of the definition of fairness, they are essentially subject to\nan incomplete definition of fairness (3). Having to 'use' an incomplete\ndefinition of fairness is considered unfair from the perspective of the\nindividual whose context is missing.\n\nInhibiting discussion, or somehow inhibiting stakeholders from actively\nparticipating in that discussion (by for example not having an open\nsituation), would therefore be unfair. Making a discussion more open\nwould improve the fairness of a system or situation.\n\n### Back to Computation\n\nWe can extend this idea to computer science and its definition on\nfairness. Considering the premise that computer science has a rather\nhomogeneous opinion on fairness, the field could indeed be better off\nhaving more people that can contribute to the definitions of fairness in\ncomputational systems. We will avoid a larger topic on the other end of\nthe discussion (having individuals not be part of the discussion might\nsometimes be a good thing)[^7] since it does not apply to the current\nscenario.\n\nThis does depend on the openness of a system. Indeed, plenty of sources\ntalk about the necessity of 'open systems' of computation and the\ndifferent risks that a lack of transparency brings to complex systems\nsuch as automated negotiation, especially when machine learning is\ninvolved (Hagras (2018), p.29).\n\nFurthermore, if fairness is regarded as something that can only be\nwell-defined in one context, how can we justifiably implement one\ndefinition in a system? Even if, hypothetically, that definition would\nfit in the context of that particular system and all of its\nstakeholders, the aforementioned definition would change over time (4).\nThis means that as the implementation ages, the context necessary for\nthe definition to be considered fair is missing.\n\nMitigating the issues with this scenario would require constant\nmaintenance on behalf of the developers, and be sure that the system\nwill _never_ be used outside of its intended context. Humans are\nnotoriously bad at _not doing_ certain things when they are told to.\n\n### Putting it Together\n\nHaving reached the end of our philosophical rabbit hole, we can start\nputting things together.\n\nThe usage of fairness in computer science is rather homogeneous, which\nis not a problem per sé, but these definitions all rely on computational\napproaches to fairness. Multiple sources mention a problem with\napproaching certain problems, including fairness, in a computational\nmatter, suggesting that there could be a better way of defining\nfairness.\n\nTo this end, we consider fairness as an essentially contested concept.\nIt tells us that fairness is a valuable attribute that is so\ncontext-sensitive that a general definition is practically impossible to\nestablish, and that any definition will only hold within the given\ncontext.\n\nLooking at fairness from this perspective implies that discussion is\nnecessary to call a system fair. Inhibiting discussion about, or\nexcluding individuals that are somehow affected by the system is\ntherefore considered unfair, and the more open the discussion regarding\na given definition of fairness, the fairer the definition.\n\n## Accessible Argumentation Drives Discussion\n\nChoosing to extend SAOP with ABN essentially means that, besides just\nproposals, arguments will are included in the negotiation. This can be\ndone in a variety of ways: at every counter-offer, only when a party\n'feels like it', etc. While the concrete usage of arguments could\ndefinitely have an effect on the fairness, we will not concern ourselves\nwith this matter in depth.\n\nBefore being able to discuss the advantages and disadvantages of\ndifferent implementations, we first have to assess if arguments even\ncontribute to fairness at all. Therefore, we will now limit ourselves to\nthe general case of how arguments contribute to fairness. In the last\nsection, we will briefly return to the point of implementation.\n\n### A Machine's Motivations\n\nHaving arguments included in a negotiation has numerous advantages.\nCertain advantages, however, are certainly more 'absolute' than others,\nwhich might depend on context if they could be considered advantages.\n\nFurthermore, this information provides insight into the machine's\nmotivations. It gives people the opportunity to reason _with_ the\nmachine, instead of about it. Reasoning about the machine requires\nknowledge of its inner workings, in turn requiring background knowledge.\nThis limits the number of stakeholders being able to participate in a\ndiscussion regarding the system.\n\nReasoning _with_ the machine, however, is possible because the agent\nshows the reasoning behind its actions. If the machine can explain\nthemselves about the current issue (e.g. their opinion on the state of\nthe negotiation, and their wishes regarding its outcome), this allows a\nstakeholder _regardless of their background_ to have an opinion on the\n_fairness of the process_[^8]. Thereby increasing the 'openness' of the\ndiscussion regarding the system.\n\nThe process of how a computational system arrives at a conclusion\ncontributes a lot more to the discussion since it provides more context.\nAs previously discussed, this context is at the heart of an essentially\ncontested concept and therefore necessary for healthy discussion. This\nallows stakeholders to have a more contextualized opinion (i.e. an\nopinion that contains contributions relevant to their definition of\nfairness (3)) on the fairness of the system.\n\nTherefore the inclusion of arguments would provide a certain\ncontextualization of the given arguments which would, given the\nimportance of context for fairness, improve the fairness of SAOP.\n\n### The Necessity of Accessible Arguments\n\nAn important assumption was the 'layman' being able to understand the\narguments of the machine. While this seems natural, it is definitely not\na given.\n\nIt should not be necessary to have a computer science degree to\nunderstand that an agent took advantage of an adversary's poor position\nin a negotiation. Whether the action of the agent is fair or not is\nunimportant. It is about a non-expert having the ability to have an\nopinion on the matter that is relevant within the context of the\nnegotiation.\n\nThis accessibility is a requirement because most stakeholders will not\nbe experts[^9]. Accessibility here refers to a non-expert being able to\nunderstand and access the arguments that are given. A person simply\nusing the negotiating agent should be able to access the argumentation\nhistory of the negotiation and understand it as if two humans were\nconversing with each other.\n\nTherefore, if non-experts cannot understand or access the arguments\ngiven by the agents, the inclusion of arguments does not improve\nfairness from the perspective of essentially contested concepts. They do\nnot provide the context which would otherwise improve a person's opinion\non the fairness of the system, and neither improve the 'openness' of the\ndiscussion as it is would be about as useful as looking through the\nsource code.\n\n### A Different Perspective\n\nWhile non-accessible arguments might not improve fairness from the\nperspective of essentially contested concepts, there are other\nadvantages to using arguments. Jennings et al. (2001) mention that it\ncan be mathematically proven that negotiations containing arguments\nconverge to a more satisfactory agreement in less time. This does not\ndirectly impact the _fairness_ of the system, but it does seem more\nrespectful towards its stakeholders to consider a system that saves them\nboth time and 'wasted' utility[^10].\n\nFurthermore, Wolff (1998) considers fairness to, in some cases, be\ninferior to respect. He proposes a solution to the issue raised before\nabout egalitarianism and people who do not contribute as much to the\ngathering of certain resources compared to others (i.e. lazy people) by\nsaying that this is 'disrespectful'.\n\nIn that case, even if the arguments are not accessible, ABN could be\nconsidered to be 'fairer' than their non-argumentation-based\ncounterparts.\n\n### There is no such Thing as Free Lunch\n\nThese advantages, however, are not without cost. There is an argument to\nbe made that having a more complex system makes it _less accessible_ to\nthe layman. Considering this, would a simpler system not be fairer if\nmore people can be more easily informed?\n\nThe costs of creating such a system are significant. Not only is the\nhuman required to understand it, but, if we want a truly\nargumentation-_based_ negotiation, the opposing agent also has to be\nable to parse and use these arguments. Doing this will require the\nadversary agent to use natural language processing to parse the passed\narguments.\n\nEven if the negotiation is not truly negotiation-based and the arguments\nare only provided to improve fairness (as an essentially contested\nconcept), these arguments still have to be created which is nowhere near\ntrivial (as alluded to before[^11]).\n\nWhile we will not discuss the feasibility, it is worth noting that it\nadds significant complexity over standard SAOP. Although not directly\nimpacting the fairness of the decisions and process of the system, it\ndoes limit the number of individuals that will be able to implement such\na system which in turn could raise several ethical considerations.\n\n## Other Remarks\n\nWhile I have tried to make this discussion as complete as possible, some\ntopics have been left undiscussed. Here, we will briefly touch upon\nthese topics before moving to the conclusion. This is definitely not an\nexhaustive list, but they are among the most important ones to consider\nfor future study.\n\nThe primary focus has been on _if_ arguments could improve fairness in\nSAOP, not by how much. In the last section we have briefly touched upon\nthis, but the practical potential of this kind of application of\narguments heavily depends on how the feasibility compares to the actual\nimprovement of fairness. This would, however, require quantifying\nfairness which would depend on a computational approach to fairness. As\nmentioned before, computational approaches to fairness have great\nadvantages. Combining the two might prove especially effective.\n\nFurthermore, while we have tried to argue that discussion is necessary\nfor all essentially contested concepts, we were only successful in doing\nso for fairness. The assumption was that fairness is valuable enough\nthat people will voice their opinion if the situation allows it (which\nis a big if in some environments), but this is hard to say for all\nessentially contested concepts.\n\nAnother undiscussed topic is that of liars, specifically, an agent lying\nin an argument. Lying in this case could either refer to making up\narguments to manipulate and gain a 'crafted' advantage over an adversary\nor by manipulating the individual reading the arguments to construct an\nopinion on the fairness of the negotiation. This could have an impact on\nthe fairness of the negotiation, but, if a deceptive agent is caught the\nbacklash would be great if the discussion is open enough (assuming most\nstakeholders do not like being deceived).\n\n## A Promising Argument\n\nSystems are going to get more complex, which is unavoidable as our\nhunger for technological advancement is insatiable. Machine learning and\nother AI techniques are already being used in automated negotiation in\nfor example opponent modeling[^12] (He et al. 2016). These computational\nmodels can and have caused significant fairness-related harms (DeBrusk\n2018; Jacobs and Wallach 2021; “Fairness in Machine Learning” 2020). It\nis therefore important we avoid similar situations arising in automated\nnegotiations.\n\nIf implemented in an accessible way (that is, in a way that non-experts\ncan access and understand), the inclusion of arguments could provide a\nway to make these systems more understandable. This would mean that\nstakeholders can create a definition of fairness for themselves with\nmore context, and it would make it easier to participate in the\ndiscussions regarding the system.\n\nThis improves fairness because we have considered open discussion\nnecessary for a fair system; the more open a discussion and the more\ninformation available about a system (since this provides more context),\nthe fairer it is. The necessity of an open discussion follows from the\nfact that we consider fairness to be an essentially contested concept.\nBeing essentially contested means that the definition of a valued\nconcept only makes sense within the context in which it is defined.\nFailing to include the context in its definition will lead to an\nincomplete (and in our case unfair) definition.\n\nEspecially where some suggest that computational approaches to fairness\nseem to cause problems (Tang and Ito 2018; Jacobs and Wallach 2021),\nthis approach to fairness could provide a promising argument for the use\nof arguments in SAOP.\n\n## Responsible Research\n\nHaving written this argument for a more accessible and open type of\nnegotiation protocol, my hope is that this document can have a positive\neffect on the fairness and trustworthiness of these systems and the\npeople influenced by it.\n\nSince this document is specifically an analysis about fairness and how\nto improve it, I will not cover the ethical implications of defining\nfairness as such, seeing as it has been extensively covered throughout.\n\nIt is also appropriate to mention that most assumptions have been based\non prior research which has been properly referenced and mentioned where\nappropriate. Equally, factual statements all refer to their respective\nsources. Wherever this is not the case, it has been indicated that this\nis my own opinion, assumption, or intuition.\n\n## References\n\n<div id=\"refs\" class=\"references csl-bib-body hanging-indent\">\n\n<div id=\"ref-aydoganAlternatingOffersProtocols2017\" class=\"csl-entry\">\n\nAydoğan, Reyhan, David Festen, Koen V. Hindriks, and Catholijn M.\nJonker. 2017. “Alternating Offers Protocols for Multilateral\nNegotiation.” In _Modern Approaches to <span class=\"nocase\">Agent-based\nComplex Automated Negotiation</span>_, edited by Katsuhide Fujita, Quan\nBai, Takayuki Ito, Minjie Zhang, Fenghui Ren, Reyhan Aydoğan, and Rafik\nHadfi, 153–67. Studies in Computational Intelligence. Cham: Springer\nInternational Publishing.\n<https://doi.org/10.1007/978-3-319-51563-2_10>.\n\n</div>\n\n<div id=\"ref-baarslagWhenWillNegotiation2017\" class=\"csl-entry\">\n\nBaarslag, Tim, Michael Kaisers, Enrico H. Gerding, Catholijn M. Jonker,\nand Jonathan Gratch. 2017. “When Will Negotiation Agents Be Able to\nRepresent Us? The Challenges and Opportunities for Autonomous\nNegotiators.” _2017_, 4684–90.\n<https://doi.org/10.24963/ijcai.2017/653>.\n\n</div>\n\n<div id=\"ref-carmelOpponentModelingMultiagent1996\" class=\"csl-entry\">\n\nCarmel, David, and Shaul Markovitch. 1996. “Opponent Modeling in\nMulti-Agent Systems.” In _Adaption and Learning in Multi-Agent Systems_,\nedited by Gerhard Weiß and Sandip Sen, 40–52. Lecture Notes in Computer\nScience. Berlin, Heidelberg: Springer.\n<https://doi.org/10.1007/3-540-60923-7_18>.\n\n</div>\n\n<div id=\"ref-cerboneProvidingPhilosophicalCritique2021\"\nclass=\"csl-entry\">\n\nCerbone, Henry. 2021. “Providing a Philosophical Critique and Guidance\nof Fairness Metrics.” _arXiv:2111.04417 \\[Cs\\]_, October.\n<https://doi.org/10.48550/arXiv.2111.04417>.\n\n</div>\n\n<div id=\"ref-debruskRiskMachineLearningBias2018\" class=\"csl-entry\">\n\nDeBrusk, Chris. 2018. “The Risk of Machine-Learning Bias (and How to\nPrevent It).” _MIT Sloan Management Review_, March.\n<https://sloanreview.mit.edu/article/the-risk-of-machine-learning-bias-and-how-to-prevent-it/>.\n\n</div>\n\n<div id=\"ref-dworkFairnessAwareness2011\" class=\"csl-entry\">\n\nDwork, Cynthia, Moritz Hardt, Toniann Pitassi, Omer Reingold, and Rich\nZemel. 2011. “Fairness Through Awareness.” _arXiv:1104.3913 \\[Cs\\]_,\nNovember. <http://arxiv.org/abs/1104.3913>.\n\n</div>\n\n<div id=\"ref-FairnessMachineLearning2020\" class=\"csl-entry\">\n\n“Fairness in Machine Learning.” 2020. _Science in the News_.\n<https://sitn.hms.harvard.edu/uncategorized/2020/fairness-machine-learning/>.\n\n</div>\n\n<div id=\"ref-gallieEssentiallyContestedConcepts1955\" class=\"csl-entry\">\n\nGallie, W. B. 1955. “Essentially Contested Concepts.” _Proceedings of\nthe Aristotelian Society_ 56: 167–98.\n<http://www.jstor.org/stable/4544562>.\n\n</div>\n\n<div id=\"ref-hagrasHumanUnderstandableExplainableAI2018\"\nclass=\"csl-entry\">\n\nHagras, Hani. 2018. “Toward Human-Understandable, Explainable AI.”\n_Computer_ 51 (9): 28–36. <https://doi.org/10.1109/MC.2018.3620965>.\n\n</div>\n\n<div id=\"ref-heOpponentModelingDeep2016\" class=\"csl-entry\">\n\nHe, He, Jordan Boyd-Graber, Kevin Kwok, and I. I. I. Hal Daumé. 2016.\n“Opponent Modeling in Deep Reinforcement Learning.” In _Proceedings of\nThe 33rd International Conference on Machine Learning_, 1804–13. PMLR.\n<https://proceedings.mlr.press/v48/he16.html>.\n\n</div>\n\n<div id=\"ref-jacobsMeasurementFairness2021a\" class=\"csl-entry\">\n\nJacobs, Abigail Z., and Hanna Wallach. 2021. “Measurement and Fairness.”\nIn _Proceedings of the 2021 ACM Conference on Fairness, Accountability,\nand Transparency_, 375–85. FAccT ’21. New York, NY, USA: Association for\nComputing Machinery. <https://doi.org/10.1145/3442188.3445901>.\n\n</div>\n\n<div id=\"ref-jenningsAutomatedNegotiationProspects2001\"\nclass=\"csl-entry\">\n\nJennings, N. R., P. Faratin, A. R. Lomuscio, S. Parsons, M. J.\nWooldridge, and C. Sierra. 2001. “Automated Negotiation: Prospects,\nMethods and Challenges.” _Group Decision and Negotiation_ 10 (2):\n199–215. <https://doi.org/10.1023/A:1008746126376>.\n\n</div>\n\n<div id=\"ref-kuhnStructureScientificRevolutions1996\" class=\"csl-entry\">\n\nKuhn, Thomas S. 1996. _The Structure of Scientific Revolutions_. 3rd ed.\nChicago: University of Chicago Press.\n<http://catdir.loc.gov/catdir/toc/uchi051/96013195.html>.\n\n</div>\n\n<div id=\"ref-neumayerDeathPenaltyAbolition2008\" class=\"csl-entry\">\n\nNeumayer, Eric. 2008. “Death Penalty Abolition and the Ratification of\nthe Second Optional Protocol.” _The International Journal of Human\nRights_ 12 (1): 3–21. <https://doi.org/10.1080/13642980701725160>.\n\n</div>\n\n<div id=\"ref-pessachAlgorithmicFairness2020\" class=\"csl-entry\">\n\nPessach, Dana, and Erez Shmueli. 2020. “Algorithmic Fairness.”\n_arXiv:2001.09784 \\[Cs, Stat\\]_, January.\n<https://doi.org/10.48550/arXiv.2001.09784>.\n\n</div>\n\n<div id=\"ref-rahwanArgumentationBasedNegotiation2004\" class=\"csl-entry\">\n\nRahwan, Iyad, Sarvapali Ramchurn, Nicholas Jennings, Peter Mcburney, and\nSimon Parsons. 2004. “Argumentation-Based Negotiation.” _The Knowledge\nEngineering Review_ 18 (January).\n<https://doi.org/10.1017/S0269888904000098>.\n\n</div>\n\n<div id=\"ref-rawlsTheoryJustice1973\" class=\"csl-entry\">\n\nRawls, John. 1973. _A Theory of Justice_. New ed. Oxford Paperbacks ; 301. Oxford: Oxford University Press.\n\n</div>\n\n<div id=\"ref-tangMetricEvaluatingNegotiation2018\" class=\"csl-entry\">\n\nTang, Xun, and Takayuki Ito. 2018. “Metric for Evaluating Negotiation\nProcess in Automated Negotiation.” In _2018 IEEE International\nConference on Agents (ICA)_, 26–29.\n<https://doi.org/10.1109/AGENTS.2018.8460127>.\n\n</div>\n\n<div id=\"ref-wolffFairnessRespectEgalitarian1998\" class=\"csl-entry\">\n\nWolff, Jonathan. 1998. “Fairness, Respect, and the Egalitarian Ethos.”\n_Philosophy & Public Affairs_ 27 (2): 97–122.\n<https://doi.org/10.1111/j.1088-4963.1998.tb00063.x>.\n\n</div>\n\n</div>\n\n[^1]:\n    _Opponent modeling_ is when one tries to estimate the preference\n    profile of their adversary. This allows for more selective\n    consideration of bids and, by extension, a quicker resolution of the\n    negotiation process (Carmel and Markovitch 1996).\n\n[^2]:\n    For brevity, I will often refer to SAOP and ABN as \"the\n    protocols\". Even though, as mentioned before, this is not\n    technically correct.\n\n[^3]:\n    I'm oversimplifying here, but that is exactly the point. There are\n    nuances to the term depending on your stance. Even including them,\n    counterarguments are rarely in short supply.\n\n[^4]:\n    I'm oversimplifying here, but that is exactly the point. There are\n    nuances to the term depending on your stance. Even including them,\n    counterarguments are rarely in short supply.\n\n[^5]:\n    In this discussion, I will use the term essentially contested\n    concept and fairness interchangeably for the purposes of\n    readability. Anything said in this section applies to all\n    essentially contested concepts, unless explicitly mentioned that it\n    is not.\n\n[^6]:\n    Importantly, it does not mean that a discussion is _sufficient_\n    for something to be a essentially contested (i.e. discussion implies\n    essentially contestedness).\n\n[^7]:\n    There are, of course, scenarios in which one would be better of\n    excluding certain people from the discussion. Especially if people\n    are uninformed, or worse, _think they are informed_ about a certain\n    context of fairness. But this is out of scope of the discussion and\n    not applicable to the current scenario of complex systems, since\n    problem is that there are not enough people that can have an opinion\n    on the matter.\n\n[^8]:\n    This does require a computer to express its motivations and\n    reasoning in natural language. Recent advancements in the field of\n    _eXplainable Artificial Intelligence_, _XAI_, have shown some\n    progress towards this goal (Hagras 2018).\n\n[^9]:\n    Here, we refer to an expert as someone with the knowledge required\n    to create such an agent (i.e. a computer scientist).\n\n[^10]:\n    _Utility_ refers to the amount personal value, or reward, of\n    something. In this case, it refers to the value of the outcome of a\n    negotiation. Each party will have their own value attributed to the\n    outcome, so they will attribute different _utility_ to it.\n\n[^11]:\n    This does require a computer to express its motivations and\n    reasoning in natural language. Recent advancements in the field of\n    _eXplainable Artificial Intelligence_, _XAI_, have shown some\n    progress towards this goal (Hagras 2018).\n\n[^12]:\n    _Opponent modeling_ is when one tries to estimate the preference\n    profile of their adversary. This allows for more selective\n    consideration of bids and, by extension, a quicker resolution of the\n    negotiation process (Carmel and Markovitch 1996).\n"},"__N_SSG":true}