<!DOCTYPE html><html lang="en-US"><head><meta charSet="utf-8"/><meta name="viewport" content="width=device-width"/><title>Fairness by Discussion</title><meta property="og:type" content="article"/><meta property="og:title" content="Fairness by Discussion"/><meta property="og:description"/><meta property="og:image"/><meta name="twitter:card" content="summary_large_image"/><meta name="next-head-count" content="8"/><link rel="apple-touch-icon" sizes="180x180" href="/apple-touch-icon.png"/><link rel="icon" type="image/png" sizes="32x32" href="/favicon-32x32.png"/><link rel="icon" type="image/png" sizes="16x16" href="/favicon-16x16.png"/><link rel="manifest" href="/site.webmanifest"/><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.8/dist/katex.min.css" integrity="sha384-GvrOXuhMATgEsSwCs4smul74iXGOixntILdUW9XmUC6+HX0sLNAK3q71HotJqlAn" crossorigin="anonymous"/><script>if (localStorage.theme === 'dark' || (!('theme' in localStorage) && window.matchMedia('(prefers-color-scheme: dark)').matches)) {           document.documentElement.classList.add('dark')             } else {           document.documentElement.classList.remove('dark')             }</script><link rel="preload" href="/_next/static/css/c1d346a475f2dc76.css" as="style"/><link rel="stylesheet" href="/_next/static/css/c1d346a475f2dc76.css" data-n-g=""/><noscript data-n-css=""></noscript><script defer="" nomodule="" src="/_next/static/chunks/polyfills-c67a75d1b6f99dc8.js"></script><script src="/_next/static/chunks/webpack-69bfa6990bb9e155.js" defer=""></script><script src="/_next/static/chunks/framework-e70c6273bfe3f237.js" defer=""></script><script src="/_next/static/chunks/main-7e27d3add388512d.js" defer=""></script><script src="/_next/static/chunks/pages/_app-1ab394c7a000adfc.js" defer=""></script><script src="/_next/static/chunks/175675d1-0bdd1afc02fe15fb.js" defer=""></script><script src="/_next/static/chunks/985-e85a3fa4ed34a036.js" defer=""></script><script src="/_next/static/chunks/pages/posts/%5Bslug%5D-b523656a8b39cc3a.js" defer=""></script><script src="/_next/static/z_8vHzP3gM3WpBWa9iOcb/_buildManifest.js" defer=""></script><script src="/_next/static/z_8vHzP3gM3WpBWa9iOcb/_ssgManifest.js" defer=""></script></head><body><div id="__next" data-reactroot=""><div class="flex flex-col min-h-screen"><header id="TOP" class="py-4 px-8"><div class="container max-w-3xl mx-auto flex justify-between"><a class="font-mono no-underline" href="/">~/</a><div class="font-mono my-auto text-accent-1-light dark:text-accent-1-dark"><span class="hidden sm:block ">cochaviz</span> <span class="block sm:hidden">üë®‚Äçüíª</span> </div><div class="flex gap-x-5"><a href="https://www.github.com/cochaviz"> github </a><a href="https://www.linkedin.com/in/cochaviz"> linkedin </a><button id="dark-mode-toggle-light" class="hover:border-accent-1-dark border-background-alt-dark bg-background-dark border-2 px-2 hidden dark:block">light mode</button><button id="dark-mode-toggle-dark" class="hover:border-accent-1-light border-background-alt-light bg-background-light border-2 px-2 block dark:hidden">dark mode</button></div></div></header><main class="container max-w-2xl"><div><a class="text-5xl font-sans no-underline fixed bottom-5 right-5 sm:bottom-10 sm:right-10 z-50 bg-background-light dark:bg-background-dark border-border-light dark:border-border-dark px-3 pb-2 border-2" href="#TOP">‚Üë</a><h1>Fairness by Discussion</h1><abstract><h3 class="no-underline">Abstract</h3> <p>The field of automated negotiation promises to improve negotiations, thus, a fair outcome and process should also be considered when building these systems. However, issues exist with computational approaches to fairness with which the field of computer science is mainly concerned. To this end, we propose a new approach to fairness based on that of essentially contested concepts to see if argumentation-based negotiation could be used as an extension to the Stacked Alternating Offers Protocol to improve fairness. Looking at fairness as an essentially contested concept shows that discussion between people somehow influenced by the negotiation system is necessary to maintain its fairness. This in turn means that systems that provide accessible context are fairer than systems that would not do so. Thus arguments, if implemented in an accessible manner, add more context to the negotiation, in turn making an SAOP negotiation fairer.</p></abstract><article><h2>Introduction</h2>
<p>Fairness in computation, especially machine learning is a topic that has
gotten increasing attention, and with good reason. COMPAS was a
statistical tool that aided some U.S. states in determining how likely
an individual was to recommit a crime. The tool, however, could display
significant racial bias towards black individuals further reinforcing
bias in human decision-making (‚ÄúFairness in Machine Learning‚Äù 2020).</p>
<p>Another field trying to augment human decision-making using computation
is that of automated negotiation. It promises to improve the outcome,
and process of negotiations by assisting humans or replacing them
altogether (Baarslag et al.¬†2017). To be clear, there have not been such
drastic fairness-related harms in automated negotiation, but that does
not mean there never will be. Especially since machine learning tools
are also being used to improve the performance of these negotiating
agents (the computer program negotiating on behalf of a party) in, for
example, opponent modeling<sup><a id="footnote-ref-1" href="#footnote-1" data-footnote-ref aria-describedby="footnote-label">1</a></sup> (He et al.¬†2016).</p>
<p>This raises the question: Would there be a way in which we could improve
the fairness of automated negotiations? The question in and of itself is
too broad and has to be scoped down in order to be meaningfully
answered. Starting with fairness and the eternal discussion regarding
the subject.</p>
<h3>Fairness is Hard</h3>
<p>Giving a single good definition of fairness is in no way trivial.
Something Gallie (1955) also observed. In his research, he coined the
term of an <em>essentially contested concept</em>, which tries to answer the
questions of why some concepts are to hard to define in a general
context.</p>
<p>Fairness being an essentially contested concept could imply that on some
topics there cannot be a single agreed definition. If that is the case,
perhaps creating a system in which definitions are more easily
investigated and adapted could be considered fairer.</p>
<p>The relevance of an essentially contested concept is further emphasized
by the history of fairness in philosophy. Simply look at the number of
opinions on fairness, or most any topic, all taking vastly different
angles in an attempt to define the concept (Rawls 1973; Wolff 1998).</p>
<p>Even though there is discussion around fairness in computer science, the
discussion does not seem to be as diverse as in philosophy. In a lot of
research, similar approaches are taken and mostly based on computational
or statistical approaches to fairness (Cerbone 2021; Jacobs and Wallach
2021).</p>
<p>Although using computational approaches to the topic makes sense in the
context of computer science, some researchers have raised concerns about
computational approaches to fairness (Jacobs and Wallach 2021). This
further motivates the need for a different approach to fairness in
computation and thus automated negotiations.</p>
<h3>On Negotiation</h3>
<p>One way in which we could influence the fairness of negotiations is by
establishing certain rules one has to follow during the negotiation. The
set of rules followed during a negotiation is called a <em>negotiation
protocol</em>.</p>
<p>One example of such a protocol is <em>SAOP</em> or the <em>Stacked Alternating
Offers Protocol</em> (Aydoƒüan et al.¬†2017). In this protocol parties present
proposals in an alternating fashion, with one party initiating the
process. At each proposal, the other party (or parties) can choose to
accept the offer, or propose a counter-offer , to which the other party
can respond again by accepting or proposing a counter-offer, etc. This
protocol is one of the most basic ones, pay attention next time you
haggle for a new car at the dealer, most probably you will follow the
rules of SAOP.</p>
<p>If you decide to rely on a seller‚Äôs empathy by arguing that you really
cannot afford that price, you are employing an <em>Argumentation Based
Negotiation</em> protocol or <em>ABN</em> protocol. While not technically a
complete protocol, allowing the usage of arguments is part of a
protocol<sup><a id="footnote-ref-2" href="#footnote-2" data-footnote-ref aria-describedby="footnote-label">2</a></sup>. In these types of negotiations, a party is allowed to
provide reasoning behind their proposal in order to inform, or possibly
manipulate, an adversary (Rahwan et al.¬†2004).</p>
<p>These kinds of negotiations are interesting because they contain more
information about the motivations of a party than SAOP. Especially in
the context of automated negotiations as we will be able to see why an
agent makes certain decisions (Rahwan et al.¬†2004). Furthermore, they
can be mathematically proven to be able to allow parties to reach a more
satisfying agreement more quickly (Jennings et al.¬†(2001), p.205).</p>
<p>Of course, more properties of negotiations exist. Another elementary
example is direct negotiation between two individuals, called a
<em>bilateral negotiation</em>. This differs from, for example, the negotiation
method used when buying a house where a real estate agent acts as a
<em>mediator</em> through which the parties bid. In addition to these two,
there is a more ‚Äògeneral‚Äô type of negotiation, namely a <em>multilateral</em>
negotiation. Simply said, this type of negotiation is one in which more
than two parties are involved.</p>
<h3>Outline</h3>
<p>Given that the usage of arguments provides a great advantage, it is
interesting to investigate if it could be considered as an extension to
SAOP to improve fairness. The simplicity of SAOP makes it a good
candidate for determining how much fairer a negotiation would be <em>with</em>
arguments instead of <em>without</em> since we will be able to focus solely on
the impact arguments have on the fairness of a negotiation.</p>
<p>To this end, we consider the fairness of SAOP and that of ABN in the
context of fairness as an essentially contested concept. In short, with
this definition, we will be able to consider fairness for automated
negotiations without having to solely rely on computations. We thus take
a different angle at the problem than other approaches in computer
science (Pessach and Shmueli 2020; Cerbone 2021; Dwork et al.¬†2011),
allowing us to resolve concerns some researchers have raised about such
approaches (Jacobs and Wallach 2021; DeBrusk 2018).</p>
<p>Because of its importance, we will start with a larger discussion on
fairness in <span class="spurious-link"
target="Fairness by Discussion"><em>Fairness by Discussion</em></span> in which
we will cover how we define fairness and why. After that we consider the
impact arguments would have on the fairness of SAOP in
<span class="spurious-link"
target="Accessible Argumentation Drives Discussion"><em>Accessible
Argumentation Drives Discussion</em></span>. We discuss some topics for
future study or discussion in <span class="spurious-link"
target="Other Remarks"><em>Other Remarks</em></span> and conclude the argument
in <span class="spurious-link" target="A Promising Argument"><em>A
Promising Argument</em></span>.</p>
<h2>Fairness by Discussion</h2>
<p>To assess the protocols in terms of <em>fairness</em>, the term has to be
properly defined. In this section, we will briefly explore current ideas
on fairness in computer science and philosophy in
<span class="spurious-link" target="A Brief History of Fairness"><em>A
Brief History of Fairness</em></span>. Following that, we will further
explain what an essentially contested concept is and why [[Fairness is
Essentially Contested][Fairness is Essentially Contested]]. We then
argue why discussion is necessary for an essentially contested concept
in <span class="spurious-link"
target="The Necessity of Open Discussion"><em>The Necessity of Open
Discussion</em></span>, reflect back on what that means for fairness in
<span class="spurious-link" target="Back to Computation"><em>Back to
Computation</em></span>, and summarize our findings in
<span class="spurious-link" target="Putting it Together"><em>Putting it
Together</em></span>.</p>
<h3>A Brief History of Fairness</h3>
<p>Plenty of work exists on fairness in philosophy. One example is that of
Wolff, who considers fairness as follows:</p>
<blockquote>
<p>Fairness is the demand that no one should be advantaged or
disadvantaged by arbitrary factors. (Wolff (1998), p.106)</p>
</blockquote>
<p>The question then becomes, what is an <em>arbitrary factor</em>? and what does
it mean to gain an advantage (or disadvantage) over someone else? While
these questions have been answered in numerous ways within the realm of
philosophy (Wolff 1998; Cerbone 2021; Rawls 1973), computer science is
rather homogeneous in its opinion of fairness. Most popular answers fall
somewhere in between a <em>Rawlsian</em> and <em>egalitarian</em> view of the
distribution of goods or services (Pessach and Shmueli 2020; Cerbone
2021).</p>
<p>There has been a growing amount of research into resolving these issues
related to computational fairness, mainly through the awareness of bias,
both in systems and culture (DeBrusk 2018; Pessach and Shmueli 2020).
This gives researchers and policymakers great tools to determine where
‚Äòunfairness‚Äô could originate from but does not solve the question of
what explicitly would be unfair.</p>
<p>Good reasons do exist for computer science to use the definitions of
fairness it does now. As an example, in Dwork et al.¬†(2011) the
definition of fairness is a statistical model of ‚Äòsimilar individuals
should be treated similarly‚Äô; similar distributions should have similar
mappings. Maximizing fairness is then a matter of minimizing the
distance between the distributions after the mapping. These models are
relatively easy to implement, quantifiable, and therefore easier to
analyze than more ‚Äòtypical‚Äô philosophical descriptions of fairness (the
theories that take 20 pages to explain, and 20 years to understand).</p>
<p>Problems, however, exist with ‚Äòcomputable‚Äô approaches to fairness. There
is a potential for some significant fairness-related harms that come
with computational systems, as mentioned by Jacobs and Wallach (2021).
They argue that fairness cannot be computed without essentially
simplifying some parts of it. In turn, leading to possibly unfair
scenarios because of simplifications that might be justifiable in all
scenarios in which the model is used.</p>
<p>Of course, this does not imply that no good definition of fairness
exists in certain contexts, but it does go to show how contested the
topic is. Current computational approaches to fairness seem to do
exactly as described; they somehow try to compute fairness. Which is the
cause of the problems mentioned by Jacobs and Wallach (2021) and Kuhn
(1996).</p>
<p>Having a definition that is independent of computation could therefore
be a good contributor to the discussion. This brings us back to the
essentially contested nature of fairness and how it relates to
discussions.</p>
<h3>Fairness is Essentially Contested</h3>
<p>We have previously given an informal definition of an essentially
contested concept, but the definition is more exact and has important
implications for our discussion. Formally, Gallie (1955) states four
conditions a concept should satisfy to be considered essentially
contested:</p>
<ol>
<li>It must be appraisive in the sense that it signifies or accredits
some kind of valued achievement (Gallie (1955), p.171).</li>
<li>This achievement must be of an internally complex character, for all
that its worth attributed to it as a whole (Gallie (1955), p.171).</li>
<li>Any explanation of its worth must therefore include reference to the
respective contributions of its various parts or feature (Gallie
(1955), p.172).</li>
<li>The accredited achievement must be of a kind that admits of
considerable modification in the light of changing circumstances;
and such modification cannot be prescribed or predicted in advance
(Gallie (1955), p.172).</li>
</ol>
<p>In short, it is a concept that should (1) signify value, (2) be
multidimensional, i.e.¬†there are multiple factors that all contribute to
something being regarded as the concept, (3) it can only be <em>properly</em>
defined in context (the definition must therefore refer to its
contributions), and (4) be time-dependent. It is a concept that is
considered valuable/important, but its definition is volatile concerning
context.</p>
<p>(1) Fairness is a valuable feature, there has been a lot of research
in <em>trying</em> to improve fairness in systems (computational as well as
organizational), as covered in the previous section. You will rarely
hear someone talk about trying to minimize the fairness of a system
unless they are in a particularly sadistic mood.</p>
<p>(2) Often, fairness does depend on more than one factor at once. Take
again the definition of fairness in terms of ‚Äòarbitrary factors‚Äô which,
quite literally, depends on (the lack of) multiple factors. A less
obvious example would be that of <em>Rawlsian</em> fairness which depends on an
individual being able to be ignorant of his position in society (Rawls
1973) to form a fair judgment. This depends on an individual being able
to be ignorant to extend that one is not able to ‚Äòsee‚Äô their position in
society, but not to such so far such that they are not aware of any
other‚Äôs position in said society, and it depends on those individuals
being ‚Äòrational‚Äô and ‚Äòfree persons‚Äô (Rawls (1973), p.11), etc.</p>
<p>(3) Furthermore, fairness is only well-defined within context. It is
not hard to think of counterexamples of any type of fairness if the
context in which it does hold is not part of the definition. Take for
example <em>egalitarianism</em>, which is the belief that resources should be
shared equally<sup><a id="footnote-ref-3" href="#footnote-3" data-footnote-ref aria-describedby="footnote-label">3</a></sup> (Wolff 1998). But what if the individuals do not put
in the same amount of work to collect those resources? The definition
should therefore be: Resources will be shared equally among those who
put in a similar amount of work<sup><a id="footnote-ref-4" href="#footnote-4" data-footnote-ref aria-describedby="footnote-label">4</a></sup>. If the context is not well-defined,
the definition will be incomplete.</p>
<p>(4) Furthermore, it is hard to predict what people will find fair in
the future. Take, for example, capital punishment. While prevalent
throughout European history, most countries have now abolished the
practice and no longer consider it a fair form of punishment (Neumayer
2008).</p>
<p>Naturally, the theories presented here are slightly cherrypicked to
prove my point. These are, however, definitely not the only ones and
plenty more examples can be given.</p>
<h3>The Necessity of Open Discussion</h3>
<p>Assuming that fairness is an essentially contested concept, we can
explore the relation between essentially contested concepts<sup><a id="footnote-ref-5" href="#footnote-5" data-footnote-ref aria-describedby="footnote-label">5</a></sup> and
discussions. This relation will show how arguments could contribute to a
more fair system.</p>
<p>The lack of a discussion about any concept could indicate a couple of
things: (I) either an agreement, (II) an ‚Äòagreement on disagreeing‚Äô, or
simply (III) not realizing that there is a disagreement. We will go
through each scenario, arguing why it would imply that discussion is
eventually necessary if that concept is essentially contested.</p>
<p>(I) If there is an actual agreement, it means some definition is
accepted. Considering that points (3) and (4) infer exactly that there
is no single definition (since it is so sensitive to context) for an
essentially contested concept, this implies that a discussion is
necessary for an essentially contested concept<sup><a id="footnote-ref-6" href="#footnote-6" data-footnote-ref aria-describedby="footnote-label">6</a></sup>. Both because of the
simple passage of time that implies that the definition changes (4), and
because different people have different backgrounds, i.e.¬†different
contexts in which they think about fairness.</p>
<p>(II) Secondly, the moment two parties decide not to discuss the topic,
it does not mean that the discussion will never arise. We can argue that
because of the valuable nature of an essentially contested concept (1),
people will have to argue about it at some point. This will, however,
only be the case if the subject is valuable enough.</p>
<p>Fairness could be considered valuable enough to eventually give rise to
discussions. If one feels like they are being treated in unfairly, and
the situation is <em>open</em>, most anyone will say that they do not agree.
Here, open, refers to a situation in which if an individual were to
voice their opinion on fairness they know that their context will be
‚Äòadded‚Äô to the definition of fairness. This means that more open
discussions contain more context, and therefore fairer, definition of
fairness.</p>
<p>(III) In the last case, since the concept is regarded as valued (1),
we can again assume that, even if parties have not yet voiced their
opinions, they will at some point do so. Thus concluding that discussion
is indeed necessary for fairness as an essentially contested concept.</p>
<p>On the other hand, what happens if an individual cannot take part in the
discussion? If individuals that are influenced by the given definition
of a concept cannot contribute to the definition, i.e.¬†their context is
not part of the definition of fairness, they are essentially subject to
an incomplete definition of fairness (3). Having to ‚Äòuse‚Äô an incomplete
definition of fairness is considered unfair from the perspective of the
individual whose context is missing.</p>
<p>Inhibiting discussion, or somehow inhibiting stakeholders from actively
participating in that discussion (by for example not having an open
situation), would therefore be unfair. Making a discussion more open
would improve the fairness of a system or situation.</p>
<h3>Back to Computation</h3>
<p>We can extend this idea to computer science and its definition on
fairness. Considering the premise that computer science has a rather
homogeneous opinion on fairness, the field could indeed be better off
having more people that can contribute to the definitions of fairness in
computational systems. We will avoid a larger topic on the other end of
the discussion (having individuals not be part of the discussion might
sometimes be a good thing)<sup><a id="footnote-ref-7" href="#footnote-7" data-footnote-ref aria-describedby="footnote-label">7</a></sup> since it does not apply to the current
scenario.</p>
<p>This does depend on the openness of a system. Indeed, plenty of sources
talk about the necessity of ‚Äòopen systems‚Äô of computation and the
different risks that a lack of transparency brings to complex systems
such as automated negotiation, especially when machine learning is
involved (Hagras (2018), p.29).</p>
<p>Furthermore, if fairness is regarded as something that can only be
well-defined in one context, how can we justifiably implement one
definition in a system? Even if, hypothetically, that definition would
fit in the context of that particular system and all of its
stakeholders, the aforementioned definition would change over time (4).
This means that as the implementation ages, the context necessary for
the definition to be considered fair is missing.</p>
<p>Mitigating the issues with this scenario would require constant
maintenance on behalf of the developers, and be sure that the system
will <em>never</em> be used outside of its intended context. Humans are
notoriously bad at <em>not doing</em> certain things when they are told to.</p>
<h3>Putting it Together</h3>
<p>Having reached the end of our philosophical rabbit hole, we can start
putting things together.</p>
<p>The usage of fairness in computer science is rather homogeneous, which
is not a problem per s√©, but these definitions all rely on computational
approaches to fairness. Multiple sources mention a problem with
approaching certain problems, including fairness, in a computational
matter, suggesting that there could be a better way of defining
fairness.</p>
<p>To this end, we consider fairness as an essentially contested concept.
It tells us that fairness is a valuable attribute that is so
context-sensitive that a general definition is practically impossible to
establish, and that any definition will only hold within the given
context.</p>
<p>Looking at fairness from this perspective implies that discussion is
necessary to call a system fair. Inhibiting discussion about, or
excluding individuals that are somehow affected by the system is
therefore considered unfair, and the more open the discussion regarding
a given definition of fairness, the fairer the definition.</p>
<h2>Accessible Argumentation Drives Discussion</h2>
<p>Choosing to extend SAOP with ABN essentially means that, besides just
proposals, arguments will are included in the negotiation. This can be
done in a variety of ways: at every counter-offer, only when a party
‚Äòfeels like it‚Äô, etc. While the concrete usage of arguments could
definitely have an effect on the fairness, we will not concern ourselves
with this matter in depth.</p>
<p>Before being able to discuss the advantages and disadvantages of
different implementations, we first have to assess if arguments even
contribute to fairness at all. Therefore, we will now limit ourselves to
the general case of how arguments contribute to fairness. In the last
section, we will briefly return to the point of implementation.</p>
<h3>A Machine‚Äôs Motivations</h3>
<p>Having arguments included in a negotiation has numerous advantages.
Certain advantages, however, are certainly more ‚Äòabsolute‚Äô than others,
which might depend on context if they could be considered advantages.</p>
<p>Furthermore, this information provides insight into the machine‚Äôs
motivations. It gives people the opportunity to reason <em>with</em> the
machine, instead of about it. Reasoning about the machine requires
knowledge of its inner workings, in turn requiring background knowledge.
This limits the number of stakeholders being able to participate in a
discussion regarding the system.</p>
<p>Reasoning <em>with</em> the machine, however, is possible because the agent
shows the reasoning behind its actions. If the machine can explain
themselves about the current issue (e.g.¬†their opinion on the state of
the negotiation, and their wishes regarding its outcome), this allows a
stakeholder <em>regardless of their background</em> to have an opinion on the
<em>fairness of the process</em><sup><a id="footnote-ref-8" href="#footnote-8" data-footnote-ref aria-describedby="footnote-label">8</a></sup>. Thereby increasing the ‚Äòopenness‚Äô of the
discussion regarding the system.</p>
<p>The process of how a computational system arrives at a conclusion
contributes a lot more to the discussion since it provides more context.
As previously discussed, this context is at the heart of an essentially
contested concept and therefore necessary for healthy discussion. This
allows stakeholders to have a more contextualized opinion (i.e.¬†an
opinion that contains contributions relevant to their definition of
fairness (3)) on the fairness of the system.</p>
<p>Therefore the inclusion of arguments would provide a certain
contextualization of the given arguments which would, given the
importance of context for fairness, improve the fairness of SAOP.</p>
<h3>The Necessity of Accessible Arguments</h3>
<p>An important assumption was the ‚Äòlayman‚Äô being able to understand the
arguments of the machine. While this seems natural, it is definitely not
a given.</p>
<p>It should not be necessary to have a computer science degree to
understand that an agent took advantage of an adversary‚Äôs poor position
in a negotiation. Whether the action of the agent is fair or not is
unimportant. It is about a non-expert having the ability to have an
opinion on the matter that is relevant within the context of the
negotiation.</p>
<p>This accessibility is a requirement because most stakeholders will not
be experts<sup><a id="footnote-ref-9" href="#footnote-9" data-footnote-ref aria-describedby="footnote-label">9</a></sup>. Accessibility here refers to a non-expert being able to
understand and access the arguments that are given. A person simply
using the negotiating agent should be able to access the argumentation
history of the negotiation and understand it as if two humans were
conversing with each other.</p>
<p>Therefore, if non-experts cannot understand or access the arguments
given by the agents, the inclusion of arguments does not improve
fairness from the perspective of essentially contested concepts. They do
not provide the context which would otherwise improve a person‚Äôs opinion
on the fairness of the system, and neither improve the ‚Äòopenness‚Äô of the
discussion as it is would be about as useful as looking through the
source code.</p>
<h3>A Different Perspective</h3>
<p>While non-accessible arguments might not improve fairness from the
perspective of essentially contested concepts, there are other
advantages to using arguments. Jennings et al.¬†(2001) mention that it
can be mathematically proven that negotiations containing arguments
converge to a more satisfactory agreement in less time. This does not
directly impact the <em>fairness</em> of the system, but it does seem more
respectful towards its stakeholders to consider a system that saves them
both time and ‚Äòwasted‚Äô utility<sup><a id="footnote-ref-10" href="#footnote-10" data-footnote-ref aria-describedby="footnote-label">10</a></sup>.</p>
<p>Furthermore, Wolff (1998) considers fairness to, in some cases, be
inferior to respect. He proposes a solution to the issue raised before
about egalitarianism and people who do not contribute as much to the
gathering of certain resources compared to others (i.e.¬†lazy people) by
saying that this is ‚Äòdisrespectful‚Äô.</p>
<p>In that case, even if the arguments are not accessible, ABN could be
considered to be ‚Äòfairer‚Äô than their non-argumentation-based
counterparts.</p>
<h3>There is no such Thing as Free Lunch</h3>
<p>These advantages, however, are not without cost. There is an argument to
be made that having a more complex system makes it <em>less accessible</em> to
the layman. Considering this, would a simpler system not be fairer if
more people can be more easily informed?</p>
<p>The costs of creating such a system are significant. Not only is the
human required to understand it, but, if we want a truly
argumentation-<em>based</em> negotiation, the opposing agent also has to be
able to parse and use these arguments. Doing this will require the
adversary agent to use natural language processing to parse the passed
arguments.</p>
<p>Even if the negotiation is not truly negotiation-based and the arguments
are only provided to improve fairness (as an essentially contested
concept), these arguments still have to be created which is nowhere near
trivial (as alluded to before<sup><a id="footnote-ref-11" href="#footnote-11" data-footnote-ref aria-describedby="footnote-label">11</a></sup>).</p>
<p>While we will not discuss the feasibility, it is worth noting that it
adds significant complexity over standard SAOP. Although not directly
impacting the fairness of the decisions and process of the system, it
does limit the number of individuals that will be able to implement such
a system which in turn could raise several ethical considerations.</p>
<h2>Other Remarks</h2>
<p>While I have tried to make this discussion as complete as possible, some
topics have been left undiscussed. Here, we will briefly touch upon
these topics before moving to the conclusion. This is definitely not an
exhaustive list, but they are among the most important ones to consider
for future study.</p>
<p>The primary focus has been on <em>if</em> arguments could improve fairness in
SAOP, not by how much. In the last section we have briefly touched upon
this, but the practical potential of this kind of application of
arguments heavily depends on how the feasibility compares to the actual
improvement of fairness. This would, however, require quantifying
fairness which would depend on a computational approach to fairness. As
mentioned before, computational approaches to fairness have great
advantages. Combining the two might prove especially effective.</p>
<p>Furthermore, while we have tried to argue that discussion is necessary
for all essentially contested concepts, we were only successful in doing
so for fairness. The assumption was that fairness is valuable enough
that people will voice their opinion if the situation allows it (which
is a big if in some environments), but this is hard to say for all
essentially contested concepts.</p>
<p>Another undiscussed topic is that of liars, specifically, an agent lying
in an argument. Lying in this case could either refer to making up
arguments to manipulate and gain a ‚Äòcrafted‚Äô advantage over an adversary
or by manipulating the individual reading the arguments to construct an
opinion on the fairness of the negotiation. This could have an impact on
the fairness of the negotiation, but, if a deceptive agent is caught the
backlash would be great if the discussion is open enough (assuming most
stakeholders do not like being deceived).</p>
<h2>A Promising Argument</h2>
<p>Systems are going to get more complex, which is unavoidable as our
hunger for technological advancement is insatiable. Machine learning and
other AI techniques are already being used in automated negotiation in
for example opponent modeling<sup><a id="footnote-ref-12" href="#footnote-12" data-footnote-ref aria-describedby="footnote-label">12</a></sup> (He et al.¬†2016). These computational
models can and have caused significant fairness-related harms (DeBrusk
2018; Jacobs and Wallach 2021; ‚ÄúFairness in Machine Learning‚Äù 2020). It
is therefore important we avoid similar situations arising in automated
negotiations.</p>
<p>If implemented in an accessible way (that is, in a way that non-experts
can access and understand), the inclusion of arguments could provide a
way to make these systems more understandable. This would mean that
stakeholders can create a definition of fairness for themselves with
more context, and it would make it easier to participate in the
discussions regarding the system.</p>
<p>This improves fairness because we have considered open discussion
necessary for a fair system; the more open a discussion and the more
information available about a system (since this provides more context),
the fairer it is. The necessity of an open discussion follows from the
fact that we consider fairness to be an essentially contested concept.
Being essentially contested means that the definition of a valued
concept only makes sense within the context in which it is defined.
Failing to include the context in its definition will lead to an
incomplete (and in our case unfair) definition.</p>
<p>Especially where some suggest that computational approaches to fairness
seem to cause problems (Tang and Ito 2018; Jacobs and Wallach 2021),
this approach to fairness could provide a promising argument for the use
of arguments in SAOP.</p>
<h2>Responsible Research</h2>
<p>Having written this argument for a more accessible and open type of
negotiation protocol, my hope is that this document can have a positive
effect on the fairness and trustworthiness of these systems and the
people influenced by it.</p>
<p>Since this document is specifically an analysis about fairness and how
to improve it, I will not cover the ethical implications of defining
fairness as such, seeing as it has been extensively covered throughout.</p>
<p>It is also appropriate to mention that most assumptions have been based
on prior research which has been properly referenced and mentioned where
appropriate. Equally, factual statements all refer to their respective
sources. Wherever this is not the case, it has been indicated that this
is my own opinion, assumption, or intuition.</p>
<h2>References</h2>
<div id="refs" class="references csl-bib-body hanging-indent">

<div id="ref-aydoganAlternatingOffersProtocols2017" class="csl-entry">

<p>Aydoƒüan, Reyhan, David Festen, Koen V. Hindriks, and Catholijn M.
Jonker. 2017. ‚ÄúAlternating Offers Protocols for Multilateral
Negotiation.‚Äù In <em>Modern Approaches to <span class="nocase">Agent-based
Complex Automated Negotiation</span></em>, edited by Katsuhide Fujita, Quan
Bai, Takayuki Ito, Minjie Zhang, Fenghui Ren, Reyhan Aydoƒüan, and Rafik
Hadfi, 153‚Äì67. Studies in Computational Intelligence. Cham: Springer
International Publishing.
<a href="https://doi.org/10.1007/978-3-319-51563-2_10">https://doi.org/10.1007/978-3-319-51563-2_10</a>.</p>
</div>

<div id="ref-baarslagWhenWillNegotiation2017" class="csl-entry">

<p>Baarslag, Tim, Michael Kaisers, Enrico H. Gerding, Catholijn M. Jonker,
and Jonathan Gratch. 2017. ‚ÄúWhen Will Negotiation Agents Be Able to
Represent Us? The Challenges and Opportunities for Autonomous
Negotiators.‚Äù <em>2017</em>, 4684‚Äì90.
<a href="https://doi.org/10.24963/ijcai.2017/653">https://doi.org/10.24963/ijcai.2017/653</a>.</p>
</div>

<div id="ref-carmelOpponentModelingMultiagent1996" class="csl-entry">

<p>Carmel, David, and Shaul Markovitch. 1996. ‚ÄúOpponent Modeling in
Multi-Agent Systems.‚Äù In <em>Adaption and Learning in Multi-Agent Systems</em>,
edited by Gerhard Wei√ü and Sandip Sen, 40‚Äì52. Lecture Notes in Computer
Science. Berlin, Heidelberg: Springer.
<a href="https://doi.org/10.1007/3-540-60923-7_18">https://doi.org/10.1007/3-540-60923-7_18</a>.</p>
</div>

<div id="ref-cerboneProvidingPhilosophicalCritique2021"
class="csl-entry">

<p>Cerbone, Henry. 2021. ‚ÄúProviding a Philosophical Critique and Guidance
of Fairness Metrics.‚Äù <em>arXiv:2111.04417 [Cs]</em>, October.
<a href="https://doi.org/10.48550/arXiv.2111.04417">https://doi.org/10.48550/arXiv.2111.04417</a>.</p>
</div>

<div id="ref-debruskRiskMachineLearningBias2018" class="csl-entry">

<p>DeBrusk, Chris. 2018. ‚ÄúThe Risk of Machine-Learning Bias (and How to
Prevent It).‚Äù <em>MIT Sloan Management Review</em>, March.
<a href="https://sloanreview.mit.edu/article/the-risk-of-machine-learning-bias-and-how-to-prevent-it/">https://sloanreview.mit.edu/article/the-risk-of-machine-learning-bias-and-how-to-prevent-it/</a>.</p>
</div>

<div id="ref-dworkFairnessAwareness2011" class="csl-entry">

<p>Dwork, Cynthia, Moritz Hardt, Toniann Pitassi, Omer Reingold, and Rich
Zemel. 2011. ‚ÄúFairness Through Awareness.‚Äù <em>arXiv:1104.3913 [Cs]</em>,
November. <a href="http://arxiv.org/abs/1104.3913">http://arxiv.org/abs/1104.3913</a>.</p>
</div>

<div id="ref-FairnessMachineLearning2020" class="csl-entry">

<p>‚ÄúFairness in Machine Learning.‚Äù 2020. <em>Science in the News</em>.
<a href="https://sitn.hms.harvard.edu/uncategorized/2020/fairness-machine-learning/">https://sitn.hms.harvard.edu/uncategorized/2020/fairness-machine-learning/</a>.</p>
</div>

<div id="ref-gallieEssentiallyContestedConcepts1955" class="csl-entry">

<p>Gallie, W. B. 1955. ‚ÄúEssentially Contested Concepts.‚Äù <em>Proceedings of
the Aristotelian Society</em> 56: 167‚Äì98.
<a href="http://www.jstor.org/stable/4544562">http://www.jstor.org/stable/4544562</a>.</p>
</div>

<div id="ref-hagrasHumanUnderstandableExplainableAI2018"
class="csl-entry">

<p>Hagras, Hani. 2018. ‚ÄúToward Human-Understandable, Explainable AI.‚Äù
<em>Computer</em> 51 (9): 28‚Äì36. <a href="https://doi.org/10.1109/MC.2018.3620965">https://doi.org/10.1109/MC.2018.3620965</a>.</p>
</div>

<div id="ref-heOpponentModelingDeep2016" class="csl-entry">

<p>He, He, Jordan Boyd-Graber, Kevin Kwok, and I. I. I. Hal Daum√©. 2016.
‚ÄúOpponent Modeling in Deep Reinforcement Learning.‚Äù In <em>Proceedings of
The 33rd International Conference on Machine Learning</em>, 1804‚Äì13. PMLR.
<a href="https://proceedings.mlr.press/v48/he16.html">https://proceedings.mlr.press/v48/he16.html</a>.</p>
</div>

<div id="ref-jacobsMeasurementFairness2021a" class="csl-entry">

<p>Jacobs, Abigail Z., and Hanna Wallach. 2021. ‚ÄúMeasurement and Fairness.‚Äù
In <em>Proceedings of the 2021 ACM Conference on Fairness, Accountability,
and Transparency</em>, 375‚Äì85. FAccT ‚Äô21. New York, NY, USA: Association for
Computing Machinery. <a href="https://doi.org/10.1145/3442188.3445901">https://doi.org/10.1145/3442188.3445901</a>.</p>
</div>

<div id="ref-jenningsAutomatedNegotiationProspects2001"
class="csl-entry">

<p>Jennings, N. R., P. Faratin, A. R. Lomuscio, S. Parsons, M. J.
Wooldridge, and C. Sierra. 2001. ‚ÄúAutomated Negotiation: Prospects,
Methods and Challenges.‚Äù <em>Group Decision and Negotiation</em> 10 (2):
199‚Äì215. <a href="https://doi.org/10.1023/A:1008746126376">https://doi.org/10.1023/A:1008746126376</a>.</p>
</div>

<div id="ref-kuhnStructureScientificRevolutions1996" class="csl-entry">

<p>Kuhn, Thomas S. 1996. <em>The Structure of Scientific Revolutions</em>. 3rd ed.
Chicago: University of Chicago Press.
<a href="http://catdir.loc.gov/catdir/toc/uchi051/96013195.html">http://catdir.loc.gov/catdir/toc/uchi051/96013195.html</a>.</p>
</div>

<div id="ref-neumayerDeathPenaltyAbolition2008" class="csl-entry">

<p>Neumayer, Eric. 2008. ‚ÄúDeath Penalty Abolition and the Ratification of
the Second Optional Protocol.‚Äù <em>The International Journal of Human
Rights</em> 12 (1): 3‚Äì21. <a href="https://doi.org/10.1080/13642980701725160">https://doi.org/10.1080/13642980701725160</a>.</p>
</div>

<div id="ref-pessachAlgorithmicFairness2020" class="csl-entry">

<p>Pessach, Dana, and Erez Shmueli. 2020. ‚ÄúAlgorithmic Fairness.‚Äù
<em>arXiv:2001.09784 [Cs, Stat]</em>, January.
<a href="https://doi.org/10.48550/arXiv.2001.09784">https://doi.org/10.48550/arXiv.2001.09784</a>.</p>
</div>

<div id="ref-rahwanArgumentationBasedNegotiation2004" class="csl-entry">

<p>Rahwan, Iyad, Sarvapali Ramchurn, Nicholas Jennings, Peter Mcburney, and
Simon Parsons. 2004. ‚ÄúArgumentation-Based Negotiation.‚Äù <em>The Knowledge
Engineering Review</em> 18 (January).
<a href="https://doi.org/10.1017/S0269888904000098">https://doi.org/10.1017/S0269888904000098</a>.</p>
</div>

<div id="ref-rawlsTheoryJustice1973" class="csl-entry">

<p>Rawls, John. 1973. <em>A Theory of Justice</em>. New ed.¬†Oxford Paperbacks ;
301. Oxford: Oxford University Press.</p>
</div>

<div id="ref-tangMetricEvaluatingNegotiation2018" class="csl-entry">

<p>Tang, Xun, and Takayuki Ito. 2018. ‚ÄúMetric for Evaluating Negotiation
Process in Automated Negotiation.‚Äù In <em>2018 IEEE International
Conference on Agents (ICA)</em>, 26‚Äì29.
<a href="https://doi.org/10.1109/AGENTS.2018.8460127">https://doi.org/10.1109/AGENTS.2018.8460127</a>.</p>
</div>

<div id="ref-wolffFairnessRespectEgalitarian1998" class="csl-entry">

<p>Wolff, Jonathan. 1998. ‚ÄúFairness, Respect, and the Egalitarian Ethos.‚Äù
<em>Philosophy &amp; Public Affairs</em> 27 (2): 97‚Äì122.
<a href="https://doi.org/10.1111/j.1088-4963.1998.tb00063.x">https://doi.org/10.1111/j.1088-4963.1998.tb00063.x</a>.</p>
</div>

</div>

<section class="footnotes" data-footnotes>
<h2 id="footnote-label" class="sr-only">Footnotes</h2>
<ol>
<li id="footnote-1">
<p><em>Opponent modeling</em> is when one tries to estimate the preference
profile of their adversary. This allows for more selective
consideration of bids and, by extension, a quicker resolution of the
negotiation process (Carmel and Markovitch 1996).<a href="#footnote-ref-1" data-footnote-backref aria-label="Back to reference 1">‚Ü©</a></p>
</li>
<li id="footnote-2">
<p>For brevity, I will often refer to SAOP and ABN as ‚Äúthe
protocols‚Äù. Even though, as mentioned before, this is not
technically correct.<a href="#footnote-ref-2" data-footnote-backref aria-label="Back to reference 2">‚Ü©</a></p>
</li>
<li id="footnote-3">
<p>I‚Äôm oversimplifying here, but that is exactly the point. There are
nuances to the term depending on your stance. Even including them,
counterarguments are rarely in short supply.<a href="#footnote-ref-3" data-footnote-backref aria-label="Back to reference 3">‚Ü©</a></p>
</li>
<li id="footnote-4">
<p>I‚Äôm oversimplifying here, but that is exactly the point. There are
nuances to the term depending on your stance. Even including them,
counterarguments are rarely in short supply.<a href="#footnote-ref-4" data-footnote-backref aria-label="Back to reference 4">‚Ü©</a></p>
</li>
<li id="footnote-5">
<p>In this discussion, I will use the term essentially contested
concept and fairness interchangeably for the purposes of
readability. Anything said in this section applies to all
essentially contested concepts, unless explicitly mentioned that it
is not.<a href="#footnote-ref-5" data-footnote-backref aria-label="Back to reference 5">‚Ü©</a></p>
</li>
<li id="footnote-6">
<p>Importantly, it does not mean that a discussion is <em>sufficient</em>
for something to be a essentially contested (i.e.¬†discussion implies
essentially contestedness).<a href="#footnote-ref-6" data-footnote-backref aria-label="Back to reference 6">‚Ü©</a></p>
</li>
<li id="footnote-7">
<p>There are, of course, scenarios in which one would be better of
excluding certain people from the discussion. Especially if people
are uninformed, or worse, <em>think they are informed</em> about a certain
context of fairness. But this is out of scope of the discussion and
not applicable to the current scenario of complex systems, since
problem is that there are not enough people that can have an opinion
on the matter.<a href="#footnote-ref-7" data-footnote-backref aria-label="Back to reference 7">‚Ü©</a></p>
</li>
<li id="footnote-8">
<p>This does require a computer to express its motivations and
reasoning in natural language. Recent advancements in the field of
<em>eXplainable Artificial Intelligence</em>, <em>XAI</em>, have shown some
progress towards this goal (Hagras 2018).<a href="#footnote-ref-8" data-footnote-backref aria-label="Back to reference 8">‚Ü©</a></p>
</li>
<li id="footnote-9">
<p>Here, we refer to an expert as someone with the knowledge required
to create such an agent (i.e.¬†a computer scientist).<a href="#footnote-ref-9" data-footnote-backref aria-label="Back to reference 9">‚Ü©</a></p>
</li>
<li id="footnote-10">
<p><em>Utility</em> refers to the amount personal value, or reward, of
something. In this case, it refers to the value of the outcome of a
negotiation. Each party will have their own value attributed to the
outcome, so they will attribute different <em>utility</em> to it.<a href="#footnote-ref-10" data-footnote-backref aria-label="Back to reference 10">‚Ü©</a></p>
</li>
<li id="footnote-11">
<p>This does require a computer to express its motivations and
reasoning in natural language. Recent advancements in the field of
<em>eXplainable Artificial Intelligence</em>, <em>XAI</em>, have shown some
progress towards this goal (Hagras 2018).<a href="#footnote-ref-11" data-footnote-backref aria-label="Back to reference 11">‚Ü©</a></p>
</li>
<li id="footnote-12">
<p><em>Opponent modeling</em> is when one tries to estimate the preference
profile of their adversary. This allows for more selective
consideration of bids and, by extension, a quicker resolution of the
negotiation process (Carmel and Markovitch 1996).<a href="#footnote-ref-12" data-footnote-backref aria-label="Back to reference 12">‚Ü©</a></p>
</li>

</ol>
</section>
</article></div></main><footer class="mt-8 p-4 px-8"><div class="container max-w-3xl mx-auto flex justify-between"><div>¬© 2023 - Zohar Cochavi</div><a href="https://github.com/cochaviz/bunkernet">check the source</a></div></footer></div></div><script id="__NEXT_DATA__" type="application/json">{"props":{"pageProps":{"frontmatter":{"abstract":"The field of automated negotiation promises to improve negotiations, thus, a fair outcome and process should also be considered when building these systems. However, issues exist with computational approaches to fairness with which the field of computer science is mainly concerned. To this end, we propose a new approach to fairness based on that of essentially contested concepts to see if argumentation-based negotiation could be used as an extension to the Stacked Alternating Offers Protocol to improve fairness. Looking at fairness as an essentially contested concept shows that discussion between people somehow influenced by the negotiation system is necessary to maintain its fairness. This in turn means that systems that provide accessible context are fairer than systems that would not do so. Thus arguments, if implemented in an accessible manner, add more context to the negotiation, in turn making an SAOP negotiation fairer.","author":"Zohar Cochavi","autoEqnLabels":false,"autoSectionLabels":false,"ccsDelim":", ","ccsLabelSep":"‚Äî","ccsTemplate":"$$i$$$$ccsLabelSep$$$$t$$","chapDelim":".","chapters":false,"chaptersDepth":1,"codeBlockCaptions":true,"cref":false,"crossrefYaml":"pandoc-crossref.yaml","date":"2022-07-02","eqLabels":"arabic","eqnBlockInlineMath":false,"eqnBlockTemplate":"\u003ctable\u003e\n\u003ccolgroup\u003e\n\u003ccol style=\"width: 90%\" /\u003e\n\u003ccol style=\"width: 10%\" /\u003e\n\u003c/colgroup\u003e\n\u003ctbody\u003e\n\u003ctr class=\"odd\"\u003e\n\u003ctd style=\"text-align: center;\"\u003e\u003cspan\nclass=\"math display\"\u003e\u003cem\u003et\u003c/em\u003e\u003c/span\u003e\u003c/td\u003e\n\u003ctd style=\"text-align: right;\"\u003e\u003cspan\nclass=\"math display\"\u003e\u003cem\u003ei\u003c/em\u003e\u003c/span\u003e\u003c/td\u003e\n\u003c/tr\u003e\n\u003c/tbody\u003e\n\u003c/table\u003e\n","eqnIndexTemplate":"($$i$$)","eqnInlineTemplate":"$$e$$$$equationNumberTeX$${$$i$$}","eqnPrefix":["eq.","eqns."],"eqnPrefixTemplate":"$$p$$¬†$$i$$","equationNumberTeX":"\\qquad","figLabels":"arabic","figPrefix":["fig.","figs."],"figPrefixTemplate":"$$p$$¬†$$i$$","figureTemplate":"$$figureTitle$$ $$i$$$$titleDelim$$ $$t$$","figureTitle":"Figure","lastDelim":", ","linkReferences":false,"listings":false,"listingTemplate":"$$listingTitle$$ $$i$$$$titleDelim$$ $$t$$","listingTitle":"Listing","listItemTitleDelim":".","lofItemTemplate":"$$lofItemTitle$$$$i$$$$listItemTitleDelim$$ $$t$$  \n","lofTitle":"# List of Figures\n","lolItemTemplate":"$$lolItemTitle$$$$i$$$$listItemTitleDelim$$ $$t$$  \n","lolTitle":"# List of Listings\n","lotItemTemplate":"$$lotItemTitle$$$$i$$$$listItemTitleDelim$$ $$t$$  \n","lotTitle":"# List of Tables\n","lstLabels":"arabic","lstPrefix":["lst.","lsts."],"lstPrefixTemplate":"$$p$$¬†$$i$$","metaDescription":"A non-computational approach to Fairness in the context of negotiations. My Bachelor‚Äôs thesis.","metaTitle":"Fairness by Discussion","nameInLink":false,"numberSections":false,"pairDelim":", ","rangeDelim":"-","refDelim":", ","refIndexTemplate":"$$i$$$$suf$$","secHeaderDelim":null,"secHeaderTemplate":"$$i$$$$secHeaderDelim[n]$$$$t$$","secLabels":"arabic","secPrefix":["sec.","secs."],"secPrefixTemplate":"$$p$$¬†$$i$$","sectionsDepth":0,"subfigGrid":false,"subfigLabels":"alpha a","subfigureChildTemplate":"$$i$$","subfigureRefIndexTemplate":"$$i$$$$suf$$ ($$s$$)","subfigureTemplate":"$$figureTitle$$ $$i$$$$titleDelim$$ $$t$$. $$ccs$$","tableEqns":false,"tableTemplate":"$$tableTitle$$ $$i$$$$titleDelim$$ $$t$$","tableTitle":"Table","tags":["thesis (bsc)","fairness","philosophy","ai"],"tblLabels":"arabic","tblPrefix":["tbl.","tbls."],"tblPrefixTemplate":"$$p$$¬†$$i$$","title":"Fairness by Discussion","titleDelim":":"},"content":"\n## Introduction\n\nFairness in computation, especially machine learning is a topic that has\ngotten increasing attention, and with good reason. COMPAS was a\nstatistical tool that aided some U.S. states in determining how likely\nan individual was to recommit a crime. The tool, however, could display\nsignificant racial bias towards black individuals further reinforcing\nbias in human decision-making (‚ÄúFairness in Machine Learning‚Äù 2020).\n\nAnother field trying to augment human decision-making using computation\nis that of automated negotiation. It promises to improve the outcome,\nand process of negotiations by assisting humans or replacing them\naltogether (Baarslag et al.¬†2017). To be clear, there have not been such\ndrastic fairness-related harms in automated negotiation, but that does\nnot mean there never will be. Especially since machine learning tools\nare also being used to improve the performance of these negotiating\nagents (the computer program negotiating on behalf of a party) in, for\nexample, opponent modeling[^1] (He et al.¬†2016).\n\nThis raises the question: Would there be a way in which we could improve\nthe fairness of automated negotiations? The question in and of itself is\ntoo broad and has to be scoped down in order to be meaningfully\nanswered. Starting with fairness and the eternal discussion regarding\nthe subject.\n\n### Fairness is Hard\n\nGiving a single good definition of fairness is in no way trivial.\nSomething Gallie (1955) also observed. In his research, he coined the\nterm of an *essentially contested concept*, which tries to answer the\nquestions of why some concepts are to hard to define in a general\ncontext.\n\nFairness being an essentially contested concept could imply that on some\ntopics there cannot be a single agreed definition. If that is the case,\nperhaps creating a system in which definitions are more easily\ninvestigated and adapted could be considered fairer.\n\nThe relevance of an essentially contested concept is further emphasized\nby the history of fairness in philosophy. Simply look at the number of\nopinions on fairness, or most any topic, all taking vastly different\nangles in an attempt to define the concept (Rawls 1973; Wolff 1998).\n\nEven though there is discussion around fairness in computer science, the\ndiscussion does not seem to be as diverse as in philosophy. In a lot of\nresearch, similar approaches are taken and mostly based on computational\nor statistical approaches to fairness (Cerbone 2021; Jacobs and Wallach\n2021).\n\nAlthough using computational approaches to the topic makes sense in the\ncontext of computer science, some researchers have raised concerns about\ncomputational approaches to fairness (Jacobs and Wallach 2021). This\nfurther motivates the need for a different approach to fairness in\ncomputation and thus automated negotiations.\n\n### On Negotiation\n\nOne way in which we could influence the fairness of negotiations is by\nestablishing certain rules one has to follow during the negotiation. The\nset of rules followed during a negotiation is called a *negotiation\nprotocol*.\n\nOne example of such a protocol is *SAOP* or the *Stacked Alternating\nOffers Protocol* (Aydoƒüan et al.¬†2017). In this protocol parties present\nproposals in an alternating fashion, with one party initiating the\nprocess. At each proposal, the other party (or parties) can choose to\naccept the offer, or propose a counter-offer , to which the other party\ncan respond again by accepting or proposing a counter-offer, etc. This\nprotocol is one of the most basic ones, pay attention next time you\nhaggle for a new car at the dealer, most probably you will follow the\nrules of SAOP.\n\nIf you decide to rely on a seller‚Äôs empathy by arguing that you really\ncannot afford that price, you are employing an *Argumentation Based\nNegotiation* protocol or *ABN* protocol. While not technically a\ncomplete protocol, allowing the usage of arguments is part of a\nprotocol[^2]. In these types of negotiations, a party is allowed to\nprovide reasoning behind their proposal in order to inform, or possibly\nmanipulate, an adversary (Rahwan et al.¬†2004).\n\nThese kinds of negotiations are interesting because they contain more\ninformation about the motivations of a party than SAOP. Especially in\nthe context of automated negotiations as we will be able to see why an\nagent makes certain decisions (Rahwan et al.¬†2004). Furthermore, they\ncan be mathematically proven to be able to allow parties to reach a more\nsatisfying agreement more quickly (Jennings et al.¬†(2001), p.205).\n\nOf course, more properties of negotiations exist. Another elementary\nexample is direct negotiation between two individuals, called a\n*bilateral negotiation*. This differs from, for example, the negotiation\nmethod used when buying a house where a real estate agent acts as a\n*mediator* through which the parties bid. In addition to these two,\nthere is a more ‚Äògeneral‚Äô type of negotiation, namely a *multilateral*\nnegotiation. Simply said, this type of negotiation is one in which more\nthan two parties are involved.\n\n### Outline\n\nGiven that the usage of arguments provides a great advantage, it is\ninteresting to investigate if it could be considered as an extension to\nSAOP to improve fairness. The simplicity of SAOP makes it a good\ncandidate for determining how much fairer a negotiation would be *with*\narguments instead of *without* since we will be able to focus solely on\nthe impact arguments have on the fairness of a negotiation.\n\nTo this end, we consider the fairness of SAOP and that of ABN in the\ncontext of fairness as an essentially contested concept. In short, with\nthis definition, we will be able to consider fairness for automated\nnegotiations without having to solely rely on computations. We thus take\na different angle at the problem than other approaches in computer\nscience (Pessach and Shmueli 2020; Cerbone 2021; Dwork et al.¬†2011),\nallowing us to resolve concerns some researchers have raised about such\napproaches (Jacobs and Wallach 2021; DeBrusk 2018).\n\nBecause of its importance, we will start with a larger discussion on\nfairness in \u003cspan class=\"spurious-link\"\ntarget=\"Fairness by Discussion\"\u003e*Fairness by Discussion*\u003c/span\u003e in which\nwe will cover how we define fairness and why. After that we consider the\nimpact arguments would have on the fairness of SAOP in\n\u003cspan class=\"spurious-link\"\ntarget=\"Accessible Argumentation Drives Discussion\"\u003e*Accessible\nArgumentation Drives Discussion*\u003c/span\u003e. We discuss some topics for\nfuture study or discussion in \u003cspan class=\"spurious-link\"\ntarget=\"Other Remarks\"\u003e*Other Remarks*\u003c/span\u003e and conclude the argument\nin \u003cspan class=\"spurious-link\" target=\"A Promising Argument\"\u003e*A\nPromising Argument*\u003c/span\u003e.\n\n## Fairness by Discussion\n\nTo assess the protocols in terms of *fairness*, the term has to be\nproperly defined. In this section, we will briefly explore current ideas\non fairness in computer science and philosophy in\n\u003cspan class=\"spurious-link\" target=\"A Brief History of Fairness\"\u003e*A\nBrief History of Fairness*\u003c/span\u003e. Following that, we will further\nexplain what an essentially contested concept is and why \\[\\[Fairness is\nEssentially Contested\\]\\[Fairness is Essentially Contested\\]\\]. We then\nargue why discussion is necessary for an essentially contested concept\nin \u003cspan class=\"spurious-link\"\ntarget=\"The Necessity of Open Discussion\"\u003e*The Necessity of Open\nDiscussion*\u003c/span\u003e, reflect back on what that means for fairness in\n\u003cspan class=\"spurious-link\" target=\"Back to Computation\"\u003e*Back to\nComputation*\u003c/span\u003e, and summarize our findings in\n\u003cspan class=\"spurious-link\" target=\"Putting it Together\"\u003e*Putting it\nTogether*\u003c/span\u003e.\n\n### A Brief History of Fairness\n\nPlenty of work exists on fairness in philosophy. One example is that of\nWolff, who considers fairness as follows:\n\n\u003e Fairness is the demand that no one should be advantaged or\n\u003e disadvantaged by arbitrary factors. (Wolff (1998), p.106)\n\nThe question then becomes, what is an *arbitrary factor*? and what does\nit mean to gain an advantage (or disadvantage) over someone else? While\nthese questions have been answered in numerous ways within the realm of\nphilosophy (Wolff 1998; Cerbone 2021; Rawls 1973), computer science is\nrather homogeneous in its opinion of fairness. Most popular answers fall\nsomewhere in between a *Rawlsian* and *egalitarian* view of the\ndistribution of goods or services (Pessach and Shmueli 2020; Cerbone\n2021).\n\nThere has been a growing amount of research into resolving these issues\nrelated to computational fairness, mainly through the awareness of bias,\nboth in systems and culture (DeBrusk 2018; Pessach and Shmueli 2020).\nThis gives researchers and policymakers great tools to determine where\n‚Äòunfairness‚Äô could originate from but does not solve the question of\nwhat explicitly would be unfair.\n\nGood reasons do exist for computer science to use the definitions of\nfairness it does now. As an example, in Dwork et al.¬†(2011) the\ndefinition of fairness is a statistical model of ‚Äòsimilar individuals\nshould be treated similarly‚Äô; similar distributions should have similar\nmappings. Maximizing fairness is then a matter of minimizing the\ndistance between the distributions after the mapping. These models are\nrelatively easy to implement, quantifiable, and therefore easier to\nanalyze than more ‚Äòtypical‚Äô philosophical descriptions of fairness (the\ntheories that take 20 pages to explain, and 20 years to understand).\n\nProblems, however, exist with ‚Äòcomputable‚Äô approaches to fairness. There\nis a potential for some significant fairness-related harms that come\nwith computational systems, as mentioned by Jacobs and Wallach (2021).\nThey argue that fairness cannot be computed without essentially\nsimplifying some parts of it. In turn, leading to possibly unfair\nscenarios because of simplifications that might be justifiable in all\nscenarios in which the model is used.\n\nOf course, this does not imply that no good definition of fairness\nexists in certain contexts, but it does go to show how contested the\ntopic is. Current computational approaches to fairness seem to do\nexactly as described; they somehow try to compute fairness. Which is the\ncause of the problems mentioned by Jacobs and Wallach (2021) and Kuhn\n(1996).\n\nHaving a definition that is independent of computation could therefore\nbe a good contributor to the discussion. This brings us back to the\nessentially contested nature of fairness and how it relates to\ndiscussions.\n\n### Fairness is Essentially Contested\n\nWe have previously given an informal definition of an essentially\ncontested concept, but the definition is more exact and has important\nimplications for our discussion. Formally, Gallie (1955) states four\nconditions a concept should satisfy to be considered essentially\ncontested:\n\n1.  It must be appraisive in the sense that it signifies or accredits\n    some kind of valued achievement (Gallie (1955), p.171).\n2.  This achievement must be of an internally complex character, for all\n    that its worth attributed to it as a whole (Gallie (1955), p.171).\n3.  Any explanation of its worth must therefore include reference to the\n    respective contributions of its various parts or feature (Gallie\n    (1955), p.172).\n4.  The accredited achievement must be of a kind that admits of\n    considerable modification in the light of changing circumstances;\n    and such modification cannot be prescribed or predicted in advance\n    (Gallie (1955), p.172).\n\nIn short, it is a concept that should (1) signify value, (2) be\nmultidimensional, i.e.¬†there are multiple factors that all contribute to\nsomething being regarded as the concept, (3) it can only be *properly*\ndefined in context (the definition must therefore refer to its\ncontributions), and (4) be time-dependent. It is a concept that is\nconsidered valuable/important, but its definition is volatile concerning\ncontext.\n\n\\(1\\) Fairness is a valuable feature, there has been a lot of research\nin *trying* to improve fairness in systems (computational as well as\norganizational), as covered in the previous section. You will rarely\nhear someone talk about trying to minimize the fairness of a system\nunless they are in a particularly sadistic mood.\n\n\\(2\\) Often, fairness does depend on more than one factor at once. Take\nagain the definition of fairness in terms of ‚Äòarbitrary factors‚Äô which,\nquite literally, depends on (the lack of) multiple factors. A less\nobvious example would be that of *Rawlsian* fairness which depends on an\nindividual being able to be ignorant of his position in society (Rawls\n1973) to form a fair judgment. This depends on an individual being able\nto be ignorant to extend that one is not able to ‚Äòsee‚Äô their position in\nsociety, but not to such so far such that they are not aware of any\nother‚Äôs position in said society, and it depends on those individuals\nbeing ‚Äòrational‚Äô and ‚Äòfree persons‚Äô (Rawls (1973), p.11), etc.\n\n\\(3\\) Furthermore, fairness is only well-defined within context. It is\nnot hard to think of counterexamples of any type of fairness if the\ncontext in which it does hold is not part of the definition. Take for\nexample *egalitarianism*, which is the belief that resources should be\nshared equally[^3] (Wolff 1998). But what if the individuals do not put\nin the same amount of work to collect those resources? The definition\nshould therefore be: Resources will be shared equally among those who\nput in a similar amount of work[^4]. If the context is not well-defined,\nthe definition will be incomplete.\n\n\\(4\\) Furthermore, it is hard to predict what people will find fair in\nthe future. Take, for example, capital punishment. While prevalent\nthroughout European history, most countries have now abolished the\npractice and no longer consider it a fair form of punishment (Neumayer\n2008).\n\nNaturally, the theories presented here are slightly cherrypicked to\nprove my point. These are, however, definitely not the only ones and\nplenty more examples can be given.\n\n### The Necessity of Open Discussion\n\nAssuming that fairness is an essentially contested concept, we can\nexplore the relation between essentially contested concepts[^5] and\ndiscussions. This relation will show how arguments could contribute to a\nmore fair system.\n\nThe lack of a discussion about any concept could indicate a couple of\nthings: (I) either an agreement, (II) an ‚Äòagreement on disagreeing‚Äô, or\nsimply (III) not realizing that there is a disagreement. We will go\nthrough each scenario, arguing why it would imply that discussion is\neventually necessary if that concept is essentially contested.\n\n\\(I\\) If there is an actual agreement, it means some definition is\naccepted. Considering that points (3) and (4) infer exactly that there\nis no single definition (since it is so sensitive to context) for an\nessentially contested concept, this implies that a discussion is\nnecessary for an essentially contested concept[^6]. Both because of the\nsimple passage of time that implies that the definition changes (4), and\nbecause different people have different backgrounds, i.e.¬†different\ncontexts in which they think about fairness.\n\n\\(II\\) Secondly, the moment two parties decide not to discuss the topic,\nit does not mean that the discussion will never arise. We can argue that\nbecause of the valuable nature of an essentially contested concept (1),\npeople will have to argue about it at some point. This will, however,\nonly be the case if the subject is valuable enough.\n\nFairness could be considered valuable enough to eventually give rise to\ndiscussions. If one feels like they are being treated in unfairly, and\nthe situation is *open*, most anyone will say that they do not agree.\nHere, open, refers to a situation in which if an individual were to\nvoice their opinion on fairness they know that their context will be\n‚Äòadded‚Äô to the definition of fairness. This means that more open\ndiscussions contain more context, and therefore fairer, definition of\nfairness.\n\n\\(III\\) In the last case, since the concept is regarded as valued (1),\nwe can again assume that, even if parties have not yet voiced their\nopinions, they will at some point do so. Thus concluding that discussion\nis indeed necessary for fairness as an essentially contested concept.\n\nOn the other hand, what happens if an individual cannot take part in the\ndiscussion? If individuals that are influenced by the given definition\nof a concept cannot contribute to the definition, i.e.¬†their context is\nnot part of the definition of fairness, they are essentially subject to\nan incomplete definition of fairness (3). Having to ‚Äòuse‚Äô an incomplete\ndefinition of fairness is considered unfair from the perspective of the\nindividual whose context is missing.\n\nInhibiting discussion, or somehow inhibiting stakeholders from actively\nparticipating in that discussion (by for example not having an open\nsituation), would therefore be unfair. Making a discussion more open\nwould improve the fairness of a system or situation.\n\n### Back to Computation\n\nWe can extend this idea to computer science and its definition on\nfairness. Considering the premise that computer science has a rather\nhomogeneous opinion on fairness, the field could indeed be better off\nhaving more people that can contribute to the definitions of fairness in\ncomputational systems. We will avoid a larger topic on the other end of\nthe discussion (having individuals not be part of the discussion might\nsometimes be a good thing)[^7] since it does not apply to the current\nscenario.\n\nThis does depend on the openness of a system. Indeed, plenty of sources\ntalk about the necessity of ‚Äòopen systems‚Äô of computation and the\ndifferent risks that a lack of transparency brings to complex systems\nsuch as automated negotiation, especially when machine learning is\ninvolved (Hagras (2018), p.29).\n\nFurthermore, if fairness is regarded as something that can only be\nwell-defined in one context, how can we justifiably implement one\ndefinition in a system? Even if, hypothetically, that definition would\nfit in the context of that particular system and all of its\nstakeholders, the aforementioned definition would change over time (4).\nThis means that as the implementation ages, the context necessary for\nthe definition to be considered fair is missing.\n\nMitigating the issues with this scenario would require constant\nmaintenance on behalf of the developers, and be sure that the system\nwill *never* be used outside of its intended context. Humans are\nnotoriously bad at *not doing* certain things when they are told to.\n\n### Putting it Together\n\nHaving reached the end of our philosophical rabbit hole, we can start\nputting things together.\n\nThe usage of fairness in computer science is rather homogeneous, which\nis not a problem per s√©, but these definitions all rely on computational\napproaches to fairness. Multiple sources mention a problem with\napproaching certain problems, including fairness, in a computational\nmatter, suggesting that there could be a better way of defining\nfairness.\n\nTo this end, we consider fairness as an essentially contested concept.\nIt tells us that fairness is a valuable attribute that is so\ncontext-sensitive that a general definition is practically impossible to\nestablish, and that any definition will only hold within the given\ncontext.\n\nLooking at fairness from this perspective implies that discussion is\nnecessary to call a system fair. Inhibiting discussion about, or\nexcluding individuals that are somehow affected by the system is\ntherefore considered unfair, and the more open the discussion regarding\na given definition of fairness, the fairer the definition.\n\n## Accessible Argumentation Drives Discussion\n\nChoosing to extend SAOP with ABN essentially means that, besides just\nproposals, arguments will are included in the negotiation. This can be\ndone in a variety of ways: at every counter-offer, only when a party\n‚Äòfeels like it‚Äô, etc. While the concrete usage of arguments could\ndefinitely have an effect on the fairness, we will not concern ourselves\nwith this matter in depth.\n\nBefore being able to discuss the advantages and disadvantages of\ndifferent implementations, we first have to assess if arguments even\ncontribute to fairness at all. Therefore, we will now limit ourselves to\nthe general case of how arguments contribute to fairness. In the last\nsection, we will briefly return to the point of implementation.\n\n### A Machine‚Äôs Motivations\n\nHaving arguments included in a negotiation has numerous advantages.\nCertain advantages, however, are certainly more ‚Äòabsolute‚Äô than others,\nwhich might depend on context if they could be considered advantages.\n\nFurthermore, this information provides insight into the machine‚Äôs\nmotivations. It gives people the opportunity to reason *with* the\nmachine, instead of about it. Reasoning about the machine requires\nknowledge of its inner workings, in turn requiring background knowledge.\nThis limits the number of stakeholders being able to participate in a\ndiscussion regarding the system.\n\nReasoning *with* the machine, however, is possible because the agent\nshows the reasoning behind its actions. If the machine can explain\nthemselves about the current issue (e.g.¬†their opinion on the state of\nthe negotiation, and their wishes regarding its outcome), this allows a\nstakeholder *regardless of their background* to have an opinion on the\n*fairness of the process*[^8]. Thereby increasing the ‚Äòopenness‚Äô of the\ndiscussion regarding the system.\n\nThe process of how a computational system arrives at a conclusion\ncontributes a lot more to the discussion since it provides more context.\nAs previously discussed, this context is at the heart of an essentially\ncontested concept and therefore necessary for healthy discussion. This\nallows stakeholders to have a more contextualized opinion (i.e.¬†an\nopinion that contains contributions relevant to their definition of\nfairness (3)) on the fairness of the system.\n\nTherefore the inclusion of arguments would provide a certain\ncontextualization of the given arguments which would, given the\nimportance of context for fairness, improve the fairness of SAOP.\n\n### The Necessity of Accessible Arguments\n\nAn important assumption was the ‚Äòlayman‚Äô being able to understand the\narguments of the machine. While this seems natural, it is definitely not\na given.\n\nIt should not be necessary to have a computer science degree to\nunderstand that an agent took advantage of an adversary‚Äôs poor position\nin a negotiation. Whether the action of the agent is fair or not is\nunimportant. It is about a non-expert having the ability to have an\nopinion on the matter that is relevant within the context of the\nnegotiation.\n\nThis accessibility is a requirement because most stakeholders will not\nbe experts[^9]. Accessibility here refers to a non-expert being able to\nunderstand and access the arguments that are given. A person simply\nusing the negotiating agent should be able to access the argumentation\nhistory of the negotiation and understand it as if two humans were\nconversing with each other.\n\nTherefore, if non-experts cannot understand or access the arguments\ngiven by the agents, the inclusion of arguments does not improve\nfairness from the perspective of essentially contested concepts. They do\nnot provide the context which would otherwise improve a person‚Äôs opinion\non the fairness of the system, and neither improve the ‚Äòopenness‚Äô of the\ndiscussion as it is would be about as useful as looking through the\nsource code.\n\n### A Different Perspective\n\nWhile non-accessible arguments might not improve fairness from the\nperspective of essentially contested concepts, there are other\nadvantages to using arguments. Jennings et al.¬†(2001) mention that it\ncan be mathematically proven that negotiations containing arguments\nconverge to a more satisfactory agreement in less time. This does not\ndirectly impact the *fairness* of the system, but it does seem more\nrespectful towards its stakeholders to consider a system that saves them\nboth time and ‚Äòwasted‚Äô utility[^10].\n\nFurthermore, Wolff (1998) considers fairness to, in some cases, be\ninferior to respect. He proposes a solution to the issue raised before\nabout egalitarianism and people who do not contribute as much to the\ngathering of certain resources compared to others (i.e.¬†lazy people) by\nsaying that this is ‚Äòdisrespectful‚Äô.\n\nIn that case, even if the arguments are not accessible, ABN could be\nconsidered to be ‚Äòfairer‚Äô than their non-argumentation-based\ncounterparts.\n\n### There is no such Thing as Free Lunch\n\nThese advantages, however, are not without cost. There is an argument to\nbe made that having a more complex system makes it *less accessible* to\nthe layman. Considering this, would a simpler system not be fairer if\nmore people can be more easily informed?\n\nThe costs of creating such a system are significant. Not only is the\nhuman required to understand it, but, if we want a truly\nargumentation-*based* negotiation, the opposing agent also has to be\nable to parse and use these arguments. Doing this will require the\nadversary agent to use natural language processing to parse the passed\narguments.\n\nEven if the negotiation is not truly negotiation-based and the arguments\nare only provided to improve fairness (as an essentially contested\nconcept), these arguments still have to be created which is nowhere near\ntrivial (as alluded to before[^11]).\n\nWhile we will not discuss the feasibility, it is worth noting that it\nadds significant complexity over standard SAOP. Although not directly\nimpacting the fairness of the decisions and process of the system, it\ndoes limit the number of individuals that will be able to implement such\na system which in turn could raise several ethical considerations.\n\n## Other Remarks\n\nWhile I have tried to make this discussion as complete as possible, some\ntopics have been left undiscussed. Here, we will briefly touch upon\nthese topics before moving to the conclusion. This is definitely not an\nexhaustive list, but they are among the most important ones to consider\nfor future study.\n\nThe primary focus has been on *if* arguments could improve fairness in\nSAOP, not by how much. In the last section we have briefly touched upon\nthis, but the practical potential of this kind of application of\narguments heavily depends on how the feasibility compares to the actual\nimprovement of fairness. This would, however, require quantifying\nfairness which would depend on a computational approach to fairness. As\nmentioned before, computational approaches to fairness have great\nadvantages. Combining the two might prove especially effective.\n\nFurthermore, while we have tried to argue that discussion is necessary\nfor all essentially contested concepts, we were only successful in doing\nso for fairness. The assumption was that fairness is valuable enough\nthat people will voice their opinion if the situation allows it (which\nis a big if in some environments), but this is hard to say for all\nessentially contested concepts.\n\nAnother undiscussed topic is that of liars, specifically, an agent lying\nin an argument. Lying in this case could either refer to making up\narguments to manipulate and gain a ‚Äòcrafted‚Äô advantage over an adversary\nor by manipulating the individual reading the arguments to construct an\nopinion on the fairness of the negotiation. This could have an impact on\nthe fairness of the negotiation, but, if a deceptive agent is caught the\nbacklash would be great if the discussion is open enough (assuming most\nstakeholders do not like being deceived).\n\n## A Promising Argument\n\nSystems are going to get more complex, which is unavoidable as our\nhunger for technological advancement is insatiable. Machine learning and\nother AI techniques are already being used in automated negotiation in\nfor example opponent modeling[^12] (He et al.¬†2016). These computational\nmodels can and have caused significant fairness-related harms (DeBrusk\n2018; Jacobs and Wallach 2021; ‚ÄúFairness in Machine Learning‚Äù 2020). It\nis therefore important we avoid similar situations arising in automated\nnegotiations.\n\nIf implemented in an accessible way (that is, in a way that non-experts\ncan access and understand), the inclusion of arguments could provide a\nway to make these systems more understandable. This would mean that\nstakeholders can create a definition of fairness for themselves with\nmore context, and it would make it easier to participate in the\ndiscussions regarding the system.\n\nThis improves fairness because we have considered open discussion\nnecessary for a fair system; the more open a discussion and the more\ninformation available about a system (since this provides more context),\nthe fairer it is. The necessity of an open discussion follows from the\nfact that we consider fairness to be an essentially contested concept.\nBeing essentially contested means that the definition of a valued\nconcept only makes sense within the context in which it is defined.\nFailing to include the context in its definition will lead to an\nincomplete (and in our case unfair) definition.\n\nEspecially where some suggest that computational approaches to fairness\nseem to cause problems (Tang and Ito 2018; Jacobs and Wallach 2021),\nthis approach to fairness could provide a promising argument for the use\nof arguments in SAOP.\n\n## Responsible Research\n\nHaving written this argument for a more accessible and open type of\nnegotiation protocol, my hope is that this document can have a positive\neffect on the fairness and trustworthiness of these systems and the\npeople influenced by it.\n\nSince this document is specifically an analysis about fairness and how\nto improve it, I will not cover the ethical implications of defining\nfairness as such, seeing as it has been extensively covered throughout.\n\nIt is also appropriate to mention that most assumptions have been based\non prior research which has been properly referenced and mentioned where\nappropriate. Equally, factual statements all refer to their respective\nsources. Wherever this is not the case, it has been indicated that this\nis my own opinion, assumption, or intuition.\n\n## References\n\n\u003cdiv id=\"refs\" class=\"references csl-bib-body hanging-indent\"\u003e\n\n\u003cdiv id=\"ref-aydoganAlternatingOffersProtocols2017\" class=\"csl-entry\"\u003e\n\nAydoƒüan, Reyhan, David Festen, Koen V. Hindriks, and Catholijn M.\nJonker. 2017. ‚ÄúAlternating Offers Protocols for Multilateral\nNegotiation.‚Äù In *Modern Approaches to \u003cspan class=\"nocase\"\u003eAgent-based\nComplex Automated Negotiation\u003c/span\u003e*, edited by Katsuhide Fujita, Quan\nBai, Takayuki Ito, Minjie Zhang, Fenghui Ren, Reyhan Aydoƒüan, and Rafik\nHadfi, 153‚Äì67. Studies in Computational Intelligence. Cham: Springer\nInternational Publishing.\n\u003chttps://doi.org/10.1007/978-3-319-51563-2_10\u003e.\n\n\u003c/div\u003e\n\n\u003cdiv id=\"ref-baarslagWhenWillNegotiation2017\" class=\"csl-entry\"\u003e\n\nBaarslag, Tim, Michael Kaisers, Enrico H. Gerding, Catholijn M. Jonker,\nand Jonathan Gratch. 2017. ‚ÄúWhen Will Negotiation Agents Be Able to\nRepresent Us? The Challenges and Opportunities for Autonomous\nNegotiators.‚Äù *2017*, 4684‚Äì90.\n\u003chttps://doi.org/10.24963/ijcai.2017/653\u003e.\n\n\u003c/div\u003e\n\n\u003cdiv id=\"ref-carmelOpponentModelingMultiagent1996\" class=\"csl-entry\"\u003e\n\nCarmel, David, and Shaul Markovitch. 1996. ‚ÄúOpponent Modeling in\nMulti-Agent Systems.‚Äù In *Adaption and Learning in Multi-Agent Systems*,\nedited by Gerhard Wei√ü and Sandip Sen, 40‚Äì52. Lecture Notes in Computer\nScience. Berlin, Heidelberg: Springer.\n\u003chttps://doi.org/10.1007/3-540-60923-7_18\u003e.\n\n\u003c/div\u003e\n\n\u003cdiv id=\"ref-cerboneProvidingPhilosophicalCritique2021\"\nclass=\"csl-entry\"\u003e\n\nCerbone, Henry. 2021. ‚ÄúProviding a Philosophical Critique and Guidance\nof Fairness Metrics.‚Äù *arXiv:2111.04417 \\[Cs\\]*, October.\n\u003chttps://doi.org/10.48550/arXiv.2111.04417\u003e.\n\n\u003c/div\u003e\n\n\u003cdiv id=\"ref-debruskRiskMachineLearningBias2018\" class=\"csl-entry\"\u003e\n\nDeBrusk, Chris. 2018. ‚ÄúThe Risk of Machine-Learning Bias (and How to\nPrevent It).‚Äù *MIT Sloan Management Review*, March.\n\u003chttps://sloanreview.mit.edu/article/the-risk-of-machine-learning-bias-and-how-to-prevent-it/\u003e.\n\n\u003c/div\u003e\n\n\u003cdiv id=\"ref-dworkFairnessAwareness2011\" class=\"csl-entry\"\u003e\n\nDwork, Cynthia, Moritz Hardt, Toniann Pitassi, Omer Reingold, and Rich\nZemel. 2011. ‚ÄúFairness Through Awareness.‚Äù *arXiv:1104.3913 \\[Cs\\]*,\nNovember. \u003chttp://arxiv.org/abs/1104.3913\u003e.\n\n\u003c/div\u003e\n\n\u003cdiv id=\"ref-FairnessMachineLearning2020\" class=\"csl-entry\"\u003e\n\n‚ÄúFairness in Machine Learning.‚Äù 2020. *Science in the News*.\n\u003chttps://sitn.hms.harvard.edu/uncategorized/2020/fairness-machine-learning/\u003e.\n\n\u003c/div\u003e\n\n\u003cdiv id=\"ref-gallieEssentiallyContestedConcepts1955\" class=\"csl-entry\"\u003e\n\nGallie, W. B. 1955. ‚ÄúEssentially Contested Concepts.‚Äù *Proceedings of\nthe Aristotelian Society* 56: 167‚Äì98.\n\u003chttp://www.jstor.org/stable/4544562\u003e.\n\n\u003c/div\u003e\n\n\u003cdiv id=\"ref-hagrasHumanUnderstandableExplainableAI2018\"\nclass=\"csl-entry\"\u003e\n\nHagras, Hani. 2018. ‚ÄúToward Human-Understandable, Explainable AI.‚Äù\n*Computer* 51 (9): 28‚Äì36. \u003chttps://doi.org/10.1109/MC.2018.3620965\u003e.\n\n\u003c/div\u003e\n\n\u003cdiv id=\"ref-heOpponentModelingDeep2016\" class=\"csl-entry\"\u003e\n\nHe, He, Jordan Boyd-Graber, Kevin Kwok, and I. I. I. Hal Daum√©. 2016.\n‚ÄúOpponent Modeling in Deep Reinforcement Learning.‚Äù In *Proceedings of\nThe 33rd International Conference on Machine Learning*, 1804‚Äì13. PMLR.\n\u003chttps://proceedings.mlr.press/v48/he16.html\u003e.\n\n\u003c/div\u003e\n\n\u003cdiv id=\"ref-jacobsMeasurementFairness2021a\" class=\"csl-entry\"\u003e\n\nJacobs, Abigail Z., and Hanna Wallach. 2021. ‚ÄúMeasurement and Fairness.‚Äù\nIn *Proceedings of the 2021 ACM Conference on Fairness, Accountability,\nand Transparency*, 375‚Äì85. FAccT ‚Äô21. New York, NY, USA: Association for\nComputing Machinery. \u003chttps://doi.org/10.1145/3442188.3445901\u003e.\n\n\u003c/div\u003e\n\n\u003cdiv id=\"ref-jenningsAutomatedNegotiationProspects2001\"\nclass=\"csl-entry\"\u003e\n\nJennings, N. R., P. Faratin, A. R. Lomuscio, S. Parsons, M. J.\nWooldridge, and C. Sierra. 2001. ‚ÄúAutomated Negotiation: Prospects,\nMethods and Challenges.‚Äù *Group Decision and Negotiation* 10 (2):\n199‚Äì215. \u003chttps://doi.org/10.1023/A:1008746126376\u003e.\n\n\u003c/div\u003e\n\n\u003cdiv id=\"ref-kuhnStructureScientificRevolutions1996\" class=\"csl-entry\"\u003e\n\nKuhn, Thomas S. 1996. *The Structure of Scientific Revolutions*. 3rd ed.\nChicago: University of Chicago Press.\n\u003chttp://catdir.loc.gov/catdir/toc/uchi051/96013195.html\u003e.\n\n\u003c/div\u003e\n\n\u003cdiv id=\"ref-neumayerDeathPenaltyAbolition2008\" class=\"csl-entry\"\u003e\n\nNeumayer, Eric. 2008. ‚ÄúDeath Penalty Abolition and the Ratification of\nthe Second Optional Protocol.‚Äù *The International Journal of Human\nRights* 12 (1): 3‚Äì21. \u003chttps://doi.org/10.1080/13642980701725160\u003e.\n\n\u003c/div\u003e\n\n\u003cdiv id=\"ref-pessachAlgorithmicFairness2020\" class=\"csl-entry\"\u003e\n\nPessach, Dana, and Erez Shmueli. 2020. ‚ÄúAlgorithmic Fairness.‚Äù\n*arXiv:2001.09784 \\[Cs, Stat\\]*, January.\n\u003chttps://doi.org/10.48550/arXiv.2001.09784\u003e.\n\n\u003c/div\u003e\n\n\u003cdiv id=\"ref-rahwanArgumentationBasedNegotiation2004\" class=\"csl-entry\"\u003e\n\nRahwan, Iyad, Sarvapali Ramchurn, Nicholas Jennings, Peter Mcburney, and\nSimon Parsons. 2004. ‚ÄúArgumentation-Based Negotiation.‚Äù *The Knowledge\nEngineering Review* 18 (January).\n\u003chttps://doi.org/10.1017/S0269888904000098\u003e.\n\n\u003c/div\u003e\n\n\u003cdiv id=\"ref-rawlsTheoryJustice1973\" class=\"csl-entry\"\u003e\n\nRawls, John. 1973. *A Theory of Justice*. New ed.¬†Oxford Paperbacks ;\n301. Oxford: Oxford University Press.\n\n\u003c/div\u003e\n\n\u003cdiv id=\"ref-tangMetricEvaluatingNegotiation2018\" class=\"csl-entry\"\u003e\n\nTang, Xun, and Takayuki Ito. 2018. ‚ÄúMetric for Evaluating Negotiation\nProcess in Automated Negotiation.‚Äù In *2018 IEEE International\nConference on Agents (ICA)*, 26‚Äì29.\n\u003chttps://doi.org/10.1109/AGENTS.2018.8460127\u003e.\n\n\u003c/div\u003e\n\n\u003cdiv id=\"ref-wolffFairnessRespectEgalitarian1998\" class=\"csl-entry\"\u003e\n\nWolff, Jonathan. 1998. ‚ÄúFairness, Respect, and the Egalitarian Ethos.‚Äù\n*Philosophy \u0026 Public Affairs* 27 (2): 97‚Äì122.\n\u003chttps://doi.org/10.1111/j.1088-4963.1998.tb00063.x\u003e.\n\n\u003c/div\u003e\n\n\u003c/div\u003e\n\n[^1]: *Opponent modeling* is when one tries to estimate the preference\n    profile of their adversary. This allows for more selective\n    consideration of bids and, by extension, a quicker resolution of the\n    negotiation process (Carmel and Markovitch 1996).\n\n[^2]: For brevity, I will often refer to SAOP and ABN as ‚Äúthe\n    protocols‚Äù. Even though, as mentioned before, this is not\n    technically correct.\n\n[^3]: I‚Äôm oversimplifying here, but that is exactly the point. There are\n    nuances to the term depending on your stance. Even including them,\n    counterarguments are rarely in short supply.\n\n[^4]: I‚Äôm oversimplifying here, but that is exactly the point. There are\n    nuances to the term depending on your stance. Even including them,\n    counterarguments are rarely in short supply.\n\n[^5]: In this discussion, I will use the term essentially contested\n    concept and fairness interchangeably for the purposes of\n    readability. Anything said in this section applies to all\n    essentially contested concepts, unless explicitly mentioned that it\n    is not.\n\n[^6]: Importantly, it does not mean that a discussion is *sufficient*\n    for something to be a essentially contested (i.e.¬†discussion implies\n    essentially contestedness).\n\n[^7]: There are, of course, scenarios in which one would be better of\n    excluding certain people from the discussion. Especially if people\n    are uninformed, or worse, *think they are informed* about a certain\n    context of fairness. But this is out of scope of the discussion and\n    not applicable to the current scenario of complex systems, since\n    problem is that there are not enough people that can have an opinion\n    on the matter.\n\n[^8]: This does require a computer to express its motivations and\n    reasoning in natural language. Recent advancements in the field of\n    *eXplainable Artificial Intelligence*, *XAI*, have shown some\n    progress towards this goal (Hagras 2018).\n\n[^9]: Here, we refer to an expert as someone with the knowledge required\n    to create such an agent (i.e.¬†a computer scientist).\n\n[^10]: *Utility* refers to the amount personal value, or reward, of\n    something. In this case, it refers to the value of the outcome of a\n    negotiation. Each party will have their own value attributed to the\n    outcome, so they will attribute different *utility* to it.\n\n[^11]: This does require a computer to express its motivations and\n    reasoning in natural language. Recent advancements in the field of\n    *eXplainable Artificial Intelligence*, *XAI*, have shown some\n    progress towards this goal (Hagras 2018).\n\n[^12]: *Opponent modeling* is when one tries to estimate the preference\n    profile of their adversary. This allows for more selective\n    consideration of bids and, by extension, a quicker resolution of the\n    negotiation process (Carmel and Markovitch 1996).\n"},"__N_SSG":true},"page":"/posts/[slug]","query":{"slug":"a-view-on-fairness-in-negotiation"},"buildId":"z_8vHzP3gM3WpBWa9iOcb","isFallback":false,"gsp":true,"scriptLoader":[]}</script></body></html>